[{"text": "Alguna vez has so\u00f1ado con tener tu", "start": 0.24, "duration": 4.039}, {"text": "propio asistente de ia totalmente", "start": 2.08, "duration": 4.6}, {"text": "personalizado visualiza esto tomas un", "start": 4.279, "duration": 4.521}, {"text": "modelo de lenguaje de talla mundial y lo", "start": 6.68, "duration": 4.48}, {"text": "conviertes en tu Aliado perfecto ya sea", "start": 8.8, "duration": 4.08}, {"text": "siguiendo tus \u00f3rdenes con precisi\u00f3n", "start": 11.16, "duration": 4.0}, {"text": "milim\u00e9trica o convirti\u00e9ndose en la", "start": 12.88, "duration": 4.96}, {"text": "m\u00e1xima autoridad en tu \u00e1rea de inter\u00e9s", "start": 15.16, "duration": 5.52}, {"text": "hoy vamos a hacer precisamente esto te", "start": 17.84, "duration": 4.76}, {"text": "mostrar\u00e9 C\u00f3mo realizar fine tuning del", "start": 20.68, "duration": 4.839}, {"text": "modelo Lama 3.1 8b de manera Ultra", "start": 22.6, "duration": 5.2}, {"text": "eficiente y completamente gratis gracias", "start": 25.519, "duration": 4.881}, {"text": "a Google colab Pero esto no es todo", "start": 27.8, "duration": 4.16}, {"text": "tambi\u00e9n descubrir\u00e1s que es realmente el", "start": 30.4, "duration": 3.92}, {"text": "fine tuning cuando aplicarlo mientras", "start": 31.96, "duration": 4.72}, {"text": "exploramos los diferentes m\u00e9todos y lo", "start": 34.32, "duration": 4.399}, {"text": "mejor de todo lo haremos paso a paso", "start": 36.68, "duration": 3.92}, {"text": "para que puedas replicarlo en tus", "start": 38.719, "duration": 4.201}, {"text": "propios proyectos No te pierdas esta", "start": 40.6, "duration": 4.0}, {"text": "oportunidad de llevar tus habilidades de", "start": 42.92, "duration": 4.08}, {"text": "ia al siguiente nivel Y prep\u00e1rate para", "start": 44.6, "duration": 5.32}, {"text": "dominar el arte del fine tuning Pues", "start": 47.0, "duration": 4.36}, {"text": "bien hoy vamos a explorar C\u00f3mo hacer", "start": 49.92, "duration": 3.479}, {"text": "fine tuning a un modelo de lenguaje de", "start": 51.36, "duration": 3.92}, {"text": "Gran escala pero no un fine tuning", "start": 53.399, "duration": 4.0}, {"text": "cualquiera sino un fine tuning de manera", "start": 55.28, "duration": 4.72}, {"text": "Ultra eficiente pero primero de todo", "start": 57.399, "duration": 4.48}, {"text": "vamos a ver qu\u00e9 es el fine tuning Pues", "start": 60.0, "duration": 3.399}, {"text": "el fine tuning es una t\u00e9cnica que", "start": 61.879, "duration": 3.881}, {"text": "consiste en tomar un modelo pre trenado", "start": 63.399, "duration": 4.561}, {"text": "de manera gen\u00e9rica y adaptarlo para que", "start": 65.76, "duration": 4.56}, {"text": "realice mejor una tarea espec\u00edfica o se", "start": 67.96, "duration": 4.479}, {"text": "comporte de una manera en particular por", "start": 70.32, "duration": 3.76}, {"text": "ejemplo en cuanto a los modelos de", "start": 72.439, "duration": 3.441}, {"text": "lenguaje de Gran escala lo que tiene que", "start": 74.08, "duration": 3.52}, {"text": "ver dentro del contexto de la generaci\u00f3n", "start": 75.88, "duration": 3.8}, {"text": "de texto podr\u00edamos entrenar un modelo", "start": 77.6, "duration": 3.92}, {"text": "para que escriba en un estilo particular", "start": 79.68, "duration": 4.6}, {"text": "como poder redactar informes t\u00e9cnicos o", "start": 81.52, "duration": 4.76}, {"text": "el caso m\u00e1s com\u00fan que solemos encontrar", "start": 84.28, "duration": 3.92}, {"text": "es ampliar el conocimiento acerca de un", "start": 86.28, "duration": 4.36}, {"text": "dominio espec\u00edfico y aqu\u00ed viene una de", "start": 88.2, "duration": 4.64}, {"text": "las preguntas m\u00e1s interesantes cu\u00e1ndo", "start": 90.64, "duration": 4.24}, {"text": "deber\u00edamos de hacer fine tuning el fine", "start": 92.84, "duration": 4.52}, {"text": "tuning es una t\u00e9cnica muy poderosa pero", "start": 94.88, "duration": 5.12}, {"text": "a la vez muy muy costosa y requiere de", "start": 97.36, "duration": 5.119}, {"text": "much\u00edsimos recursos computacionales por", "start": 100.0, "duration": 3.96}, {"text": "lo que entonces debemos seleccionar", "start": 102.479, "duration": 3.761}, {"text": "cuidadosamente Cu\u00e1ndo debemos aplicar", "start": 103.96, "duration": 4.56}, {"text": "Esta t\u00e9cnica tenemos que pensar en ser", "start": 106.24, "duration": 4.199}, {"text": "eficientes en cuanto a recursos primero", "start": 108.52, "duration": 4.199}, {"text": "de todo yendo de menor a mayor", "start": 110.439, "duration": 3.761}, {"text": "complejidad en cuanto a t\u00e9cnicas", "start": 112.719, "duration": 3.04}, {"text": "disponibles para modificar el", "start": 114.2, "duration": 3.8}, {"text": "comportamiento de los llms estas", "start": 115.759, "duration": 4.4}, {"text": "t\u00e9cnicas ya las conocemos son las", "start": 118.0, "duration": 3.96}, {"text": "t\u00e9cnicas de prompting los sistemas rack", "start": 120.159, "duration": 3.761}, {"text": "etc\u00e9tera etc\u00e9tera que ahora veremos a", "start": 121.96, "duration": 4.839}, {"text": "continuaci\u00f3n en detalle precisamente", "start": 123.92, "duration": 4.64}, {"text": "aqu\u00ed es cuando tenemos que evaluar no", "start": 126.799, "duration": 4.201}, {"text": "cu\u00e1ndo consideramos hacer fine tuning", "start": 128.56, "duration": 4.319}, {"text": "antes de pensar en hacer fine tuning", "start": 131.0, "duration": 3.56}, {"text": "deber\u00edamos de cumplir con estas tres", "start": 132.879, "duration": 4.121}, {"text": "reglas que vemos aqu\u00ed primero de todo", "start": 134.56, "duration": 3.92}, {"text": "que nos hemos encontrado con", "start": 137.0, "duration": 3.2}, {"text": "limitaciones en cuanto al prompting o", "start": 138.48, "duration": 4.839}, {"text": "los sistemas rack es decir solo si hemos", "start": 140.2, "duration": 5.2}, {"text": "probado de manera exhaustiva diferentes", "start": 143.319, "duration": 4.441}, {"text": "t\u00e9cnicas de prompting que hay much\u00edsimas", "start": 145.4, "duration": 4.52}, {"text": "hemos construido sistemas rack que es el", "start": 147.76, "duration": 4.119}, {"text": "siguiente paso en cuanto a complejidad y", "start": 149.92, "duration": 4.0}, {"text": "no hemos logrado los resultados deseados", "start": 151.879, "duration": 4.08}, {"text": "entonces aqu\u00ed s\u00ed que el fine tuning", "start": 153.92, "duration": 3.48}, {"text": "puede ser la siguiente etapa para", "start": 155.959, "duration": 3.881}, {"text": "superar estas limitaciones el siguiente", "start": 157.4, "duration": 5.199}, {"text": "punto necesitamos un grand\u00edsimo volumen", "start": 159.84, "duration": 4.84}, {"text": "de datos por lo tanto solo si disponemos", "start": 162.599, "duration": 4.801}, {"text": "de este conjunto de datos grande y", "start": 164.68, "duration": 4.24}, {"text": "representativo de la torea O del", "start": 167.4, "duration": 3.839}, {"text": "comportamiento que deseamos que el", "start": 168.92, "duration": 4.679}, {"text": "modelo adquiera entonces aqu\u00ed es cuando", "start": 171.239, "duration": 4.041}, {"text": "el fine tuning pueda aprovechar esta", "start": 173.599, "duration": 3.36}, {"text": "informaci\u00f3n para mejorar", "start": 175.28, "duration": 4.039}, {"text": "significativamente y la siguiente regla", "start": 176.959, "duration": 3.441}, {"text": "ser\u00eda", "start": 179.319, "duration": 3.321}, {"text": "que necesitamos tareas muy espec\u00edficas", "start": 180.4, "duration": 3.8}, {"text": "es decir si necesitamos que el modelo", "start": 182.64, "duration": 3.64}, {"text": "realice una tarea muy muy muy espec\u00edfica", "start": 184.2, "duration": 3.92}, {"text": "o se comporte de una manera en", "start": 186.28, "duration": 4.519}, {"text": "particular de forma consistente que no", "start": 188.12, "duration": 5.24}, {"text": "hemos logrado otra vez repito con las", "start": 190.799, "duration": 3.921}, {"text": "diferentes t\u00e9cnicas que tenemos", "start": 193.36, "duration": 3.799}, {"text": "disponibles como prompting Y rack en", "start": 194.72, "duration": 4.68}, {"text": "este momento es cuando el fine tuning", "start": 197.159, "duration": 4.521}, {"text": "puede ser pues la mejor opci\u00f3n para", "start": 199.4, "duration": 5.24}, {"text": "lograr un rendimiento \u00f3ptimo recordad", "start": 201.68, "duration": 4.76}, {"text": "siempre cumplir estas tres reglas porque", "start": 204.64, "duration": 4.319}, {"text": "si no no tiene sentido el consumo de", "start": 206.44, "duration": 4.48}, {"text": "recursos que vamos vamos a generar", "start": 208.959, "duration": 3.681}, {"text": "dentro del fine tuning existen", "start": 210.92, "duration": 4.12}, {"text": "much\u00edsimas t\u00e9cnicas Como por ejemplo", "start": 212.64, "duration": 4.04}, {"text": "estamos viendo aqu\u00ed diferentes podemos", "start": 215.04, "duration": 3.559}, {"text": "encontrar diferentes clasificaciones y", "start": 216.68, "duration": 4.08}, {"text": "dentro de cada clasificaci\u00f3n diferentes", "start": 218.599, "duration": 4.92}, {"text": "t\u00e9cnicas existen much\u00edsimas aqu\u00ed solo", "start": 220.76, "duration": 4.64}, {"text": "tengo enumeradas unas cuantas como puede", "start": 223.519, "duration": 4.161}, {"text": "ser dentro el grupo del supervise fine", "start": 225.4, "duration": 4.24}, {"text": "tuning podemos encontrar el parameter", "start": 227.68, "duration": 4.08}, {"text": "fishing fine tuning Dentro de este", "start": 229.64, "duration": 4.2}, {"text": "podemos encontrar los adapter el prefix", "start": 231.76, "duration": 4.119}, {"text": "fine tuning luego por otro lado tenemos", "start": 233.84, "duration": 4.399}, {"text": "el knowledge injection en otro grupo", "start": 235.879, "duration": 4.241}, {"text": "entrar\u00eda lo que es el reinform learning", "start": 238.239, "duration": 4.36}, {"text": "from human feedback luego tenemos otras", "start": 240.12, "duration": 4.839}, {"text": "t\u00e9cnicas en supervise fine tuning Hay", "start": 242.599, "duration": 4.521}, {"text": "much\u00edsimas hoy vamos a centrarnos", "start": 244.959, "duration": 4.881}, {"text": "espec\u00edficamente en lo que nos interesa", "start": 247.12, "duration": 5.16}, {"text": "vamos a hacer un fine tuning supervisado", "start": 249.84, "duration": 3.84}, {"text": "es decir lo que hemos visto", "start": 252.28, "duration": 3.56}, {"text": "anteriormente el supervis fine tuning es", "start": 253.68, "duration": 3.72}, {"text": "dentro del grupo que nos vamos a centrar", "start": 255.84, "duration": 4.84}, {"text": "en el d\u00eda de hoy pero qu\u00e9 es el superv", "start": 257.4, "duration": 4.88}, {"text": "fine tuning Pues bien es una t\u00e9cnica de", "start": 260.68, "duration": 4.04}, {"text": "aprendizaje por transferencia que ajusta", "start": 262.28, "duration": 4.24}, {"text": "el modelo de lenguaje pre entrenado", "start": 264.72, "duration": 3.199}, {"text": "utilizando un conjunto de datos", "start": 266.52, "duration": 3.6}, {"text": "etiquetados espec\u00edficamente para para", "start": 267.919, "duration": 3.961}, {"text": "una tarea en concreto como hemos visto", "start": 270.12, "duration": 5.04}, {"text": "antes aqu\u00ed la clave est\u00e1 en el conjunto", "start": 271.88, "duration": 5.2}, {"text": "de datos etiquetado Esto es lo que hace", "start": 275.16, "duration": 4.479}, {"text": "que sea supervisado no es una de estas", "start": 277.08, "duration": 4.679}, {"text": "caracter\u00edsticas clave que vemos aqu\u00ed el", "start": 279.639, "duration": 4.0}, {"text": "que hace que sea supervisado es que", "start": 281.759, "duration": 4.521}, {"text": "estamos utilizando datos etiquetados", "start": 283.639, "duration": 5.601}, {"text": "donde ya se conoce la respuesta correcta", "start": 286.28, "duration": 5.04}, {"text": "luego tambi\u00e9n es un proceso iterativo y", "start": 289.24, "duration": 4.04}, {"text": "el modelo se actualiza de manera gradual", "start": 291.32, "duration": 3.719}, {"text": "para minimizar la diferencia entre las", "start": 293.28, "duration": 4.0}, {"text": "predicciones y las respuestas correctas", "start": 295.039, "duration": 4.681}, {"text": "gracias a este dataset previamente", "start": 297.28, "duration": 4.28}, {"text": "generado bueno Y por \u00faltimo una de las", "start": 299.72, "duration": 3.72}, {"text": "caracter\u00edsticas clav es que preserva el", "start": 301.56, "duration": 3.639}, {"text": "conocimiento base no O sea al final", "start": 303.44, "duration": 2.92}, {"text": "mantenemos gran parte de este", "start": 305.199, "duration": 3.28}, {"text": "conocimiento general mientras lo", "start": 306.36, "duration": 4.399}, {"text": "especializamos en un \u00e1rea en concreto", "start": 308.479, "duration": 4.641}, {"text": "cu\u00e1ndo deber\u00edamos de considerar hacer el", "start": 310.759, "duration": 4.601}, {"text": "super bite fine tuning otra vez esto es", "start": 313.12, "duration": 5.44}, {"text": "un poco eh repetitivo a la diapositiva", "start": 315.36, "duration": 4.32}, {"text": "anterior pero quiero hacer mucho", "start": 318.56, "duration": 2.6}, {"text": "hincapi\u00e9 en esto porque es", "start": 319.68, "duration": 3.16}, {"text": "verdaderamente importante para ser", "start": 321.16, "duration": 3.759}, {"text": "grandes profesionales debemos pensar", "start": 322.84, "duration": 3.44}, {"text": "siempre desde el punto de vista de la", "start": 324.919, "duration": 3.681}, {"text": "eficiencia por lo tanto antes de", "start": 326.28, "duration": 4.199}, {"text": "realizar una t\u00e9cnica como el superv fine", "start": 328.6, "duration": 3.719}, {"text": "tuning primero tenemos que intentar con", "start": 330.479, "duration": 3.84}, {"text": "otras t\u00e9cnicas de ingenier\u00eda no como", "start": 332.319, "duration": 3.281}, {"text": "hemos comentado antes dentro del", "start": 334.319, "duration": 3.361}, {"text": "prompting podr\u00edamos Probar con el Fusion", "start": 335.6, "duration": 3.719}, {"text": "prompting con el Chain of thought", "start": 337.68, "duration": 4.12}, {"text": "etc\u00e9tera etc\u00e9tera previamente si no", "start": 339.319, "duration": 4.0}, {"text": "conseguimos los resultados deseados", "start": 341.8, "duration": 3.88}, {"text": "podr\u00edamos probar en construir un sistema", "start": 343.319, "duration": 4.561}, {"text": "rack no la generaci\u00f3n aumentada por", "start": 345.68, "duration": 4.92}, {"text": "recuperaci\u00f3n entonces y \u00fanicamente", "start": 347.88, "duration": 4.4}, {"text": "Entonces si estas t\u00e9cnicas no cumplen", "start": 350.6, "duration": 3.319}, {"text": "los objetivos de calidad etc\u00e9tera", "start": 352.28, "duration": 3.359}, {"text": "etc\u00e9tera es cuando podr\u00edamos considerar", "start": 353.919, "duration": 4.321}, {"text": "el superv fine tuning y como he dicho", "start": 355.639, "duration": 5.081}, {"text": "antes el superv F tuning solo es viable", "start": 358.24, "duration": 4.28}, {"text": "cuando se dispone de una grand\u00edsima", "start": 360.72, "duration": 3.84}, {"text": "cantidad de datos Y una vez tenemos", "start": 362.52, "duration": 4.519}, {"text": "estos datos los tenemos que curar es", "start": 364.56, "duration": 4.6}, {"text": "super importante O sea a veces solo se", "start": 367.039, "duration": 4.521}, {"text": "habla del proceso de entrenamiento y a", "start": 369.16, "duration": 4.24}, {"text": "veces se desmerece la importancia que", "start": 371.56, "duration": 4.16}, {"text": "tienen los datos y la calidad de los", "start": 373.4, "duration": 4.4}, {"text": "mismos cuanto mayor calidad de datos y", "start": 375.72, "duration": 4.16}, {"text": "mayor refinados est\u00e9n mejores resultados", "start": 377.8, "duration": 3.799}, {"text": "vamos a obtener con el mismo proceso de", "start": 379.88, "duration": 3.52}, {"text": "entrenamiento As\u00ed que realmente es algo", "start": 381.599, "duration": 3.921}, {"text": "muy importante Pues bien dentro de las", "start": 383.4, "duration": 4.44}, {"text": "t\u00e9cnicas del supervise fine tuning esto", "start": 385.52, "duration": 4.519}, {"text": "no pretende ser una lista ex Stan y", "start": 387.84, "duration": 4.72}, {"text": "much\u00edsimo menos existen m\u00e1s pero me voy", "start": 390.039, "duration": 4.28}, {"text": "a centrar en las tres principales para", "start": 392.56, "duration": 3.4}, {"text": "que entendamos Cu\u00e1l es la que vamos a", "start": 394.319, "duration": 4.401}, {"text": " hoy y en qu\u00e9 se diferencia o Qu\u00e9", "start": 395.96, "duration": 4.359}, {"text": "caracter\u00edsticas especiales tiene en", "start": 398.72, "duration": 4.0}, {"text": "cuanto a las otras las que vamos a", "start": 400.319, "duration": 4.081}, {"text": "entrar un poco m\u00e1s en detalle a fondo", "start": 402.72, "duration": 3.96}, {"text": "como vemos aqu\u00ed es el F fine tuning el", "start": 404.4, "duration": 4.72}, {"text": "Lora low rank adaptation y q Lora", "start": 406.68, "duration": 5.4}, {"text": "quantization aare low rank adaptation", "start": 409.12, "duration": 5.479}, {"text": "Pues bien como os dice aqu\u00ed nuestro", "start": 412.08, "duration": 4.399}, {"text": "amigo Lama primero de todo si no os", "start": 414.599, "duration": 4.681}, {"text": "hab\u00e9is suscrito al Canal no me har\u00edais", "start": 416.479, "duration": 4.84}, {"text": "un gran favor si os gusta este contenido", "start": 419.28, "duration": 4.84}, {"text": "si os suscrib\u00ed le dais a la campanita le", "start": 421.319, "duration": 5.201}, {"text": "dais like Pues bien En qu\u00e9 consiste el", "start": 424.12, "duration": 4.28}, {"text": "full fine tuning el full F tuning", "start": 426.52, "duration": 3.72}, {"text": "consiste en reentrenar todos los", "start": 428.4, "duration": 3.84}, {"text": "par\u00e1metros del modelo sabemos que estos", "start": 430.24, "duration": 4.2}, {"text": "modelos de lenguaje de Gran escala son", "start": 432.24, "duration": 4.84}, {"text": "redes neuronales no son modelos de Deep", "start": 434.44, "duration": 5.439}, {"text": "learning con una grand\u00edsima cantidad en", "start": 437.08, "duration": 5.44}, {"text": "cuanto a redes neuronales se refiere por", "start": 439.879, "duration": 4.681}, {"text": "lo que el full F tuning consistir\u00eda en", "start": 442.52, "duration": 4.239}, {"text": "reentrenar todos los par\u00e1metros de esta", "start": 444.56, "duration": 4.319}, {"text": "red neuronal alguna de las ventajas que", "start": 446.759, "duration": 4.44}, {"text": "podr\u00edamos encontrares unos mejores", "start": 448.879, "duration": 4.921}, {"text": "resultados por otro lado las desventajas", "start": 451.199, "duration": 4.921}, {"text": "muy importantes y luego lo ver\u00e9is cuando", "start": 453.8, "duration": 4.0}, {"text": "entremos en la pr\u00e1ctica sobre todo es", "start": 456.12, "duration": 3.88}, {"text": "que requiere una grand\u00edsima cantidad de", "start": 457.8, "duration": 4.679}, {"text": "recursos computacionales y luego tambi\u00e9n", "start": 460.0, "duration": 4.319}, {"text": "que puede llevar al olvido catastr\u00f3fico", "start": 462.479, "duration": 4.041}, {"text": "de habilidades previas esto tambi\u00e9n es", "start": 464.319, "duration": 4.16}, {"text": "muy importante tenerlo en cuenta la", "start": 466.52, "duration": 4.399}, {"text": "siguiente t\u00e9cnica es Lora El low rank", "start": 468.479, "duration": 5.041}, {"text": "adaptation o adaptaci\u00f3n de bajo Rango", "start": 470.919, "duration": 4.28}, {"text": "esto es una t\u00e9cnica de fine tuning que", "start": 473.52, "duration": 4.359}, {"text": "es mucho m\u00e1s eficiente en cuanto a la", "start": 475.199, "duration": 4.4}, {"text": "actualizaci\u00f3n de los par\u00e1metros", "start": 477.879, "duration": 4.04}, {"text": "porque consiste en congelar los pesos", "start": 479.599, "duration": 4.241}, {"text": "originales los pesos de las conexiones", "start": 481.919, "duration": 4.081}, {"text": "de las redes neuronales Y entonces lo", "start": 483.84, "duration": 3.479}, {"text": "que hacemos Es introducir unos", "start": 486.0, "duration": 3.599}, {"text": "adaptadores peque\u00f1os esto Qu\u00e9 ventaja", "start": 487.319, "duration": 5.801}, {"text": "supone primero de todo un menor uso de", "start": 489.599, "duration": 5.361}, {"text": "la memoria y de tiempo de entrenamiento", "start": 493.12, "duration": 4.4}, {"text": "tambi\u00e9n no es un m\u00e9todo destructivo", "start": 494.96, "duration": 4.04}, {"text": "porque como hemos dicho los los", "start": 497.52, "duration": 3.239}, {"text": "par\u00e1metros originales estos pesos los", "start": 499.0, "duration": 4.159}, {"text": "congelamos y se mantienen y estar\u00edamos", "start": 500.759, "duration": 4.961}, {"text": "entrenando en total menos del 1% de los", "start": 503.159, "duration": 4.32}, {"text": "par\u00e1metros Comparado con el full fight", "start": 505.72, "duration": 4.319}, {"text": "tuning vale la siguiente t\u00e9cnica es qora", "start": 507.479, "duration": 5.56}, {"text": "el quanti low rank adaptation o", "start": 510.039, "duration": 5.281}, {"text": "adaptaci\u00f3n de bajo Rango cuantizada el", "start": 513.039, "duration": 4.081}, {"text": "qora es una extensi\u00f3n del hora como", "start": 515.32, "duration": 4.32}, {"text": "podemos deducir por el nombre pero que", "start": 517.12, "duration": 5.159}, {"text": "nos brinda un mayor ahorro de memoria", "start": 519.64, "duration": 5.24}, {"text": "hasta un 33 por de reducci\u00f3n adicional", "start": 522.279, "duration": 5.281}, {"text": "de memoria si lo comparamos con Lora", "start": 524.88, "duration": 4.72}, {"text": "est\u00e1ndar con la t\u00e9cnica de Lora est\u00e1ndar", "start": 527.56, "duration": 4.36}, {"text": "Cu\u00e1l es la desventaja Pues que", "start": 529.6, "duration": 3.6}, {"text": "necesitamos unos tiempos de", "start": 531.92, "duration": 3.359}, {"text": "entrenamiento un poco m\u00e1s largos", "start": 533.2, "duration": 5.4}, {"text": "alrededor del 39 m\u00e1s que si hacemos un", "start": 535.279, "duration": 5.321}, {"text": "fine tuning con Lora regular con la", "start": 538.6, "duration": 5.6}, {"text": "t\u00e9cnica Lora regular pero esta opci\u00f3n es", "start": 540.6, "duration": 6.16}, {"text": "ideal cuando la memoria de la gpu es", "start": 544.2, "duration": 4.96}, {"text": "limitada como ser\u00e1 nuestro caso para", "start": 546.76, "duration": 3.68}, {"text": "entender un poco m\u00e1s esto de la", "start": 549.16, "duration": 2.88}, {"text": "cuantizaci\u00f3n porque es posible que lo", "start": 550.44, "duration": 3.959}, {"text": "hay\u00e1is o\u00eddo bastante y que no sep\u00e1is del", "start": 552.04, "duration": 5.16}, {"text": "todo de qu\u00e9 va vamos a dar una pincelada", "start": 554.399, "duration": 5.201}, {"text": "de lo que es la cuantizaci\u00f3n b\u00e1sicamente", "start": 557.2, "duration": 4.16}, {"text": "la cuantizaci\u00f3n es una t\u00e9cnica que nos", "start": 559.6, "duration": 4.44}, {"text": "permite reducir la precisi\u00f3n num\u00e9rica de", "start": 561.36, "duration": 5.08}, {"text": "los par\u00e1metros del modelo este proceso", "start": 564.04, "duration": 4.16}, {"text": "consistir\u00eda en convertir los n\u00fameros de", "start": 566.44, "duration": 5.079}, {"text": "punto flotante de 32 bits a formatos de", "start": 568.2, "duration": 6.72}, {"text": "menor precisi\u00f3n como puede ser bf16 fp16", "start": 571.519, "duration": 5.0}, {"text": "y los beneficios que encontramos al", "start": 574.92, "duration": 3.8}, {"text": "hacer esta reducci\u00f3n de precisi\u00f3n es que", "start": 576.519, "duration": 4.481}, {"text": "reducimos el tama\u00f1o del modelo total por", "start": 578.72, "duration": 4.72}, {"text": "lo tanto reducimos su consumo de memoria", "start": 581.0, "duration": 5.2}, {"text": "obtenemos inferencias m\u00e1s r\u00e1pidas y un", "start": 583.44, "duration": 5.519}, {"text": "menor consumo de energ\u00eda algo a tener en", "start": 586.2, "duration": 5.48}, {"text": "cuenta es que los modelos cuantizados", "start": 588.959, "duration": 5.12}, {"text": "normalmente tienen ligeras p\u00e9rdidas de", "start": 591.68, "duration": 4.719}, {"text": "precisi\u00f3n en cuanto a las predicciones", "start": 594.079, "duration": 4.44}, {"text": "es decir Cuanto m\u00e1s cuantizado est\u00e9 un", "start": 596.399, "duration": 4.601}, {"text": "modelo seguramente esta p\u00e9rdida ser\u00e1", "start": 598.519, "duration": 4.641}, {"text": "mayor cuanto menos cuantizado Pues esta", "start": 601.0, "duration": 4.44}, {"text": "p\u00e9rdida ser\u00e1 menor es un compromiso que", "start": 603.16, "duration": 4.2}, {"text": "tenemos que encontrar sobre todo los que", "start": 605.44, "duration": 3.6}, {"text": "trabaj\u00e1is con modelos Open source y Vais", "start": 607.36, "duration": 3.56}, {"text": "a haing faces seguramente estar\u00e9is", "start": 609.04, "duration": 4.359}, {"text": "acostumbrados a ver que hay diferentes", "start": 610.92, "duration": 4.24}, {"text": "opciones de modelos en cuanto a", "start": 613.399, "duration": 4.401}, {"text": "cuantizaci\u00f3n se refiere pues no es m\u00e1s", "start": 615.16, "duration": 5.44}, {"text": "que esto al final lo suyo es escoger la", "start": 617.8, "duration": 4.719}, {"text": "cuantizaci\u00f3n menor posible que nos", "start": 620.6, "duration": 3.52}, {"text": "permita nuestra m\u00e1quina para no", "start": 622.519, "duration": 3.721}, {"text": "comprometer lo que ser\u00eda la precisi\u00f3n de", "start": 624.12, "duration": 3.92}, {"text": "las predicciones bien y con esta", "start": 626.24, "duration": 3.719}, {"text": "pincelada vamos Vamos a entrar en", "start": 628.04, "duration": 4.28}, {"text": "detalle a hablar del laboratorio de hoy", "start": 629.959, "duration": 3.841}, {"text": "pero antes de pasar directamente al", "start": 632.32, "duration": 3.72}, {"text": "c\u00f3digo hay unas cuantas diapositivas m\u00e1s", "start": 633.8, "duration": 4.12}, {"text": "porque quiero que entend\u00e1is exactamente", "start": 636.04, "duration": 4.44}, {"text": "qu\u00e9 es lo que vamos a hacer ya que puede", "start": 637.92, "duration": 4.68}, {"text": "ser que a priori parezca un poco", "start": 640.48, "duration": 4.0}, {"text": "complejo pero ya os digo que realmente", "start": 642.6, "duration": 4.359}, {"text": "no lo es est\u00e1 todo super detallado en el", "start": 644.48, "duration": 4.52}, {"text": "Notebook que os dejar\u00e9", "start": 646.959, "duration": 4.921}, {"text": "en como ya sab\u00e9is os dejo siempre todo", "start": 649.0, "duration": 4.56}, {"text": "el c\u00f3digo en el grupo de Telegram que", "start": 651.88, "duration": 4.0}, {"text": "aprovecho para para deciros si no est\u00e1is", "start": 653.56, "duration": 4.279}, {"text": "en el grupo de Telegram aprovechad y", "start": 655.88, "duration": 5.24}, {"text": "uniros ya estamos casi personas estamos", "start": 657.839, "duration": 5.401}, {"text": "aport\u00e1ndonos mucho valor al final es un", "start": 661.12, "duration": 3.48}, {"text": "grupo abierto en el que todo el mundo", "start": 663.24, "duration": 3.76}, {"text": "puede hablar preguntar comentar sus", "start": 664.6, "duration": 4.4}, {"text": "proyectos y ah\u00ed tambi\u00e9n os voy dejando", "start": 667.0, "duration": 3.639}, {"text": "todos los recursos que voy creando en", "start": 669.0, "duration": 3.76}, {"text": "este v\u00eddeo Por lo cual all\u00ed Tambi\u00e9n", "start": 670.639, "duration": 4.0}, {"text": "encontrar\u00e9is el Notebook que como ver\u00e9is", "start": 672.76, "duration": 4.24}, {"text": "est\u00e1 super detallado para que tambi\u00e9n lo", "start": 674.639, "duration": 4.361}, {"text": "pod\u00e1is repasar tranquilamente en casa", "start": 677.0, "duration": 3.8}, {"text": "pues bien sin m\u00e1s dilaci\u00f3n En qu\u00e9", "start": 679.0, "duration": 3.639}, {"text": "consiste el app de hoy primero de todo", "start": 680.8, "duration": 3.719}, {"text": "vamos a utilizar como hemos visto dentro", "start": 682.639, "duration": 5.161}, {"text": "del campo del Super wif tuning Kora el", "start": 684.519, "duration": 5.041}, {"text": "objetivo que vamos a perseguir en", "start": 687.8, "duration": 3.88}, {"text": "laboratorio es que vamos a un", "start": 689.56, "duration": 4.399}, {"text": "modelo base y vamos a intentar adaptar", "start": 691.68, "duration": 5.599}, {"text": "su comportamiento mejorando la capacidad", "start": 693.959, "duration": 5.0}, {"text": "del mismo Para seguir instrucciones y", "start": 697.279, "duration": 4.201}, {"text": "generar respuestas apropiadas porque o", "start": 698.959, "duration": 5.401}, {"text": "sea los modelos de base no est\u00e1n", "start": 701.48, "duration": 5.2}, {"text": "especializados o preparados para seguir", "start": 704.36, "duration": 4.68}, {"text": "instrucciones precisas o sea los modelos", "start": 706.68, "duration": 5.56}, {"text": "base se est\u00e1n especializados en generar", "start": 709.04, "duration": 5.4}, {"text": "texto en predecir en base a un texto", "start": 712.24, "duration": 4.719}, {"text": "predeterminado predecir Cu\u00e1l es la", "start": 714.44, "duration": 3.959}, {"text": "siguiente estructura de texto o el", "start": 716.959, "duration": 3.44}, {"text": "siguiente contenido de texto que", "start": 718.399, "duration": 3.841}, {"text": "requiere para completar una tarea", "start": 720.399, "duration": 4.601}, {"text": "determinada por ejemplo chat gpt es un", "start": 722.24, "duration": 6.48}, {"text": "modelo que est\u00e1 fine tuneado para seguir", "start": 725.0, "duration": 5.72}, {"text": "instrucciones otra vez todos los que", "start": 728.72, "duration": 3.64}, {"text": "est\u00e1is dentro del mundo Open source", "start": 730.72, "duration": 3.76}, {"text": "seguramente ya lo sabr\u00e9is normalmente si", "start": 732.36, "duration": 4.039}, {"text": "vamos a hagin Face por ejemplo podemos", "start": 734.48, "duration": 4.4}, {"text": "encontrar Lama por ejemplo el modelo", "start": 736.399, "duration": 5.401}, {"text": "base y luego podemos encontrar el modelo", "start": 738.88, "duration": 5.0}, {"text": "cualquier modelo que pone guion it guion", "start": 741.8, "duration": 4.32}, {"text": "it significa que es instruct model es", "start": 743.88, "duration": 3.8}, {"text": "decir que es un modelo que est\u00e1 fine", "start": 746.12, "duration": 4.68}, {"text": "tuneado Espe m para poder seguir", "start": 747.68, "duration": 5.04}, {"text": "instrucciones de la misma manera que", "start": 750.8, "duration": 4.039}, {"text": "interactuamos con chat gpt directamente", "start": 752.72, "duration": 4.359}, {"text": "desde la interfaz gr\u00e1fica Y esto es lo", "start": 754.839, "duration": 4.201}, {"text": "que vamos a hacer hoy Cu\u00e1l es el proceso", "start": 757.079, "duration": 3.641}, {"text": "que vamos a seguir como hemos dicho", "start": 759.04, "duration": 3.44}, {"text": "vamos a partir de un modelo base pre", "start": 760.72, "duration": 3.88}, {"text": "entrenado en un Corpus de texto grande y", "start": 762.48, "duration": 4.28}, {"text": "diverso en este caso va a ser Lama 3.1", "start": 764.6, "duration": 4.64}, {"text": "como se ha avanzado antes utilizaremos", "start": 766.76, "duration": 4.759}, {"text": "un dataset m\u00e1s peque\u00f1o y espec\u00edfico que", "start": 769.24, "duration": 4.039}, {"text": "contiene partes entrada y salida", "start": 771.519, "duration": 4.521}, {"text": "etiquetados manualmente para poder", "start": 773.279, "duration": 5.36}, {"text": "seguir este proceso de instrucci\u00f3n Y por", "start": 776.04, "duration": 4.32}, {"text": "\u00faltimo lo que vamos a hacer es ajustar", "start": 778.639, "duration": 3.88}, {"text": "los par\u00e1metros del modelo para optimizar", "start": 780.36, "duration": 4.839}, {"text": "su rendimiento en esta \u00e1rea espec\u00edfica", "start": 782.519, "duration": 4.961}, {"text": "que es la de seguir instrucciones", "start": 785.199, "duration": 4.601}, {"text": "b\u00e1sicamente estamos adaptando el", "start": 787.48, "duration": 4.479}, {"text": "comportamiento Mejor dicho Qu\u00e9 t\u00e9cnica", "start": 789.8, "duration": 3.599}, {"text": "de supervise fine tuning vamos a", "start": 791.959, "duration": 4.281}, {"text": "utilizar pues Kora Ya lo hemos visto por", "start": 793.399, "duration": 4.721}, {"text": "qu\u00e9 Porque ofrece un ahorro sustancial", "start": 796.24, "duration": 4.68}, {"text": "de memoria es ideal para escenarios con", "start": 798.12, "duration": 5.04}, {"text": "memoria gpu limitada como es Google", "start": 800.92, "duration": 4.12}, {"text": "colab y por lo tanto al final lo que", "start": 803.16, "duration": 3.28}, {"text": "vamos a hacer Dentro de este laboratorio", "start": 805.04, "duration": 4.08}, {"text": "es utilizar kolora para ajustar la mat", "start": 806.44, "duration": 5.88}, {"text": "punto1 de 8 billions en Google colab", "start": 809.12, "duration": 5.04}, {"text": "otra cosa importante que vamos a estar", "start": 812.32, "duration": 5.04}, {"text": "utilizando aqu\u00ed es ansol junto con Lama", "start": 814.16, "duration": 6.4}, {"text": "3.1 bien porque hemos escogido laama 3.1", "start": 817.36, "duration": 4.88}, {"text": "no hace falta decirlo al final es uno de", "start": 820.56, "duration": 4.959}, {"text": "los modelos Open source m\u00e1s potentes que", "start": 822.24, "duration": 5.0}, {"text": "tenemos a nuestra disposici\u00f3n a d\u00eda de", "start": 825.519, "duration": 4.32}, {"text": "hoy por lo tanto es un candidato ideal", "start": 827.24, "duration": 4.24}, {"text": "para poder realizar este tipo de", "start": 829.839, "duration": 3.841}, {"text": "t\u00e9cnicas nos ofrece un rendimiento", "start": 831.48, "duration": 4.24}, {"text": "incre\u00edble y ya sab\u00e9is que bueno los", "start": 833.68, "duration": 4.079}, {"text": "modelos m\u00e1s grandes no el de 8 billions", "start": 835.72, "duration": 3.96}, {"text": "pero rivaliza con los modelos de c\u00f3digo", "start": 837.759, "duration": 5.0}, {"text": "cerrado como bien puede ser gemini o", "start": 839.68, "duration": 5.48}, {"text": "como bien puede ser gpt lo que vamos a", "start": 842.759, "duration": 4.401}, {"text": "hacer es ajustarlo a nuestro caso de uso", "start": 845.16, "duration": 3.599}, {"text": "espec\u00edfico para obtener mejores", "start": 847.16, "duration": 3.119}, {"text": "resultados que en este caso nuestro caso", "start": 848.759, "duration": 3.241}, {"text": "de uso espec\u00edfico es seguir", "start": 850.279, "duration": 4.041}, {"text": "instrucciones de manera precisa Y por", "start": 852.0, "duration": 3.959}, {"text": "\u00faltimo vamos a utilizar esta librer\u00eda", "start": 854.32, "duration": 4.24}, {"text": "uns solve ya que nos proporciona un", "start": 855.959, "duration": 4.921}, {"text": "entrenamiento dos veces m\u00e1s r\u00e1pido y un", "start": 858.56, "duration": 4.24}, {"text": "80% menos de uso de memoria en", "start": 860.88, "duration": 3.24}, {"text": "comparaci\u00f3n con otras opciones que", "start": 862.8, "duration": 3.52}, {"text": "podemos encontrar en el mercado lo cual", "start": 864.12, "duration": 3.959}, {"text": "lo hace ideal para un entorno limitado", "start": 866.32, "duration": 4.519}, {"text": "como es Google app y sin m\u00e1s dilaci\u00f3n", "start": 868.079, "duration": 5.641}, {"text": "como nos dice la Lama vamos a pasar al", "start": 870.839, "duration": 6.24}, {"text": "c\u00f3digo a funear nuestro modelo bien Aqu\u00ed", "start": 873.72, "duration": 6.0}, {"text": "estoy en en Google Cab primero de todo", "start": 877.079, "duration": 4.88}, {"text": "quiero hacer eh Bueno una peque\u00f1a", "start": 879.72, "duration": 3.6}, {"text": "menci\u00f3n porque ver\u00e9is que aqu\u00ed estoy", "start": 881.959, "duration": 4.921}, {"text": "utilizando la versi\u00f3n de colap Pro Plus", "start": 883.32, "duration": 5.16}, {"text": "en el v\u00eddeo he mencionado que esto se", "start": 886.88, "duration": 2.959}, {"text": "puede hacer de manera totalmente", "start": 888.48, "duration": 3.279}, {"text": "gratuita es cierto se puede hacer de", "start": 889.839, "duration": 3.961}, {"text": "manera totalmente gratuita ahora os", "start": 891.759, "duration": 4.601}, {"text": "explicar\u00e9 por qu\u00e9 yo he escogido pagar", "start": 893.8, "duration": 4.8}, {"text": "la versi\u00f3n de prop plus para poderos", "start": 896.36, "duration": 4.56}, {"text": "hacer este este tutorial As\u00ed que", "start": 898.6, "duration": 4.28}, {"text": "realmente va a ser mi v\u00eddeo m\u00e1s costoso", "start": 900.92, "duration": 4.08}, {"text": "os agradecer\u00eda otra vez que me dej\u00e9is un", "start": 902.88, "duration": 3.72}, {"text": "comentario Si os est\u00e1 gustando el v\u00eddeo", "start": 905.0, "duration": 3.759}, {"text": "que le deis Like si no est\u00e1is suscritos", "start": 906.6, "duration": 4.76}, {"text": "por favor suscribiros al Canal porque ya", "start": 908.759, "duration": 4.08}, {"text": "veis que mi intenci\u00f3n es ofreceros", "start": 911.36, "duration": 3.2}, {"text": "contenido totalmente de calidad", "start": 912.839, "duration": 4.321}, {"text": "independientemente del coste que en este", "start": 914.56, "duration": 4.56}, {"text": "caso no ha sido peque\u00f1o hasta la fecha", "start": 917.16, "duration": 4.479}, {"text": "es mi v\u00eddeo m\u00e1s caro con diferencia Pues", "start": 919.12, "duration": 5.2}, {"text": "bien Vamos a hacer fine tuning de Lama", "start": 921.639, "duration": 6.721}, {"text": "3.1 8b utilizando cul hora realmente con", "start": 924.32, "duration": 6.319}, {"text": "ansol primero de todo vamos a instalar", "start": 928.36, "duration": 5.08}, {"text": "las dependencias aqu\u00ed si veis un poquito", "start": 930.639, "duration": 4.921}, {"text": "m\u00e1s de c\u00f3digo es b\u00e1sicamente porque en", "start": 933.44, "duration": 4.48}, {"text": "funci\u00f3n o sea tenemos que comprobar Qu\u00e9", "start": 935.56, "duration": 4.8}, {"text": "versi\u00f3n de la librer\u00eda torch utiliza", "start": 937.92, "duration": 4.159}, {"text": "porque hay incompatibilidades con otra", "start": 940.36, "duration": 4.719}, {"text": "librer\u00eda que necesitamos que es xfers", "start": 942.079, "duration": 4.361}, {"text": "por lo tanto aqu\u00ed simplemente hacemos", "start": 945.079, "duration": 3.721}, {"text": "una peque\u00f1a comprobaci\u00f3n y en funci\u00f3n de", "start": 946.44, "duration": 4.16}, {"text": "la versi\u00f3n de torch pues instalamos una", "start": 948.8, "duration": 4.24}, {"text": "versi\u00f3n de xfers u otra vale lo", "start": 950.6, "duration": 4.039}, {"text": "siguiente que vamos a hacer es comprobar", "start": 953.04, "duration": 3.359}, {"text": "que tenemos un entorno con una gpu", "start": 954.639, "duration": 3.44}, {"text": "disponible porque si no O sea el", "start": 956.399, "duration": 3.081}, {"text": "siguiente import cuando intentemos", "start": 958.079, "duration": 3.921}, {"text": "importar la librer\u00eda unol va a fallar o", "start": 959.48, "duration": 5.56}, {"text": "sea necesitamos una gpu de nvidia para", "start": 962.0, "duration": 5.48}, {"text": "poder hacer este proceso de F tuning que", "start": 965.04, "duration": 4.599}, {"text": "os voy a ense\u00f1ar ahora b\u00e1sicamente esto", "start": 967.48, "duration": 4.32}, {"text": "comprueba que tenemos una gpu disponible", "start": 969.639, "duration": 4.841}, {"text": "si es as\u00ed veremos aqu\u00ed todo este", "start": 971.8, "duration": 4.24}, {"text": "cuadrito que veis aqu\u00ed esta informaci\u00f3n", "start": 974.48, "duration": 4.4}, {"text": "si no pues este cuadrito no lo tendremos", "start": 976.04, "duration": 4.719}, {"text": "y cuando import temos las librer\u00edas que", "start": 978.88, "duration": 4.36}, {"text": "vamos a utilizar en el tutorial aqu\u00ed", "start": 980.759, "duration": 4.121}, {"text": "pues el proceso", "start": 983.24, "duration": 4.0}, {"text": "petar por lo tanto pues mejor hacemos", "start": 984.88, "duration": 5.199}, {"text": "esta comprobaci\u00f3n antes", "start": 987.24, "duration": 5.079}, {"text": "vale lo primero de todo es Descargar el", "start": 990.079, "duration": 5.24}, {"text": "modelo como os comentaba el Notebook", "start": 992.319, "duration": 4.841}, {"text": "est\u00e1 super detallado con toda la", "start": 995.319, "duration": 3.88}, {"text": "informaci\u00f3n super detallada de todos los", "start": 997.16, "duration": 3.96}, {"text": "par\u00e1metros de todo lo que vamos a hacer", "start": 999.199, "duration": 4.0}, {"text": "para que os lo pod\u00e1is mirar en casa con", "start": 1001.12, "duration": 3.519}, {"text": "calma y que este v\u00eddeo sea un poquito", "start": 1003.199, "duration": 4.32}, {"text": "m\u00e1s ligero voy a comentar las que son", "start": 1004.639, "duration": 5.721}, {"text": "m\u00e1s importantes y las dem\u00e1s repito", "start": 1007.519, "duration": 4.481}, {"text": "ten\u00e9is el Notebook lo pod\u00e9is leer en", "start": 1010.36, "duration": 3.24}, {"text": "casa con calma ya que es una buen\u00edsima", "start": 1012.0, "duration": 3.959}, {"text": "gu\u00eda de estudio vale primero de todo la", "start": 1013.6, "duration": 5.28}, {"text": "secuencia m\u00e1xima como nos dice aqu\u00ed no", "start": 1015.959, "duration": 4.8}, {"text": "parar el modelo para Su uso es necesario", "start": 1018.88, "duration": 3.6}, {"text": "Establecer un l\u00edmite m\u00e1ximo para", "start": 1020.759, "duration": 3.481}, {"text": "longitud de las secuencias lo que", "start": 1022.48, "duration": 3.559}, {"text": "evidentemente va a afectar o sea lo que", "start": 1024.24, "duration": 3.439}, {"text": "estamos haciendo es el contex Windows", "start": 1026.039, "duration": 3.8}, {"text": "reducirlo va a afectar a la capacidad de", "start": 1027.679, "duration": 5.201}, {"text": "procesar informaci\u00f3n contextual como", "start": 1029.839, "duration": 5.561}, {"text": "vemos aqu\u00ed la versi\u00f3n de Lama 3.1 nos", "start": 1032.88, "duration": 3.919}, {"text": "ofrece una ventana de contexto de", "start": 1035.4, "duration": 4.36}, {"text": "128,000 tokens pero en este caso vamos a", "start": 1036.799, "duration": 5.52}, {"text": "optar por una configuraci\u00f3n m\u00e1s Modesta", "start": 1039.76, "duration": 5.12}, {"text": "para ahorrar en cuanto a consumo de eh", "start": 1042.319, "duration": 5.041}, {"text": "memoria RAM de la gpu por lo tanto lo", "start": 1044.88, "duration": 5.64}, {"text": "vamos a limitar a 2000 48 tokens vale el", "start": 1047.36, "duration": 4.96}, {"text": "siguiente par\u00e1metro que vemos aqu\u00ed es el", "start": 1050.52, "duration": 4.44}, {"text": "dtype hay diferentes opciones las ten\u00e9is", "start": 1052.32, "duration": 4.64}, {"text": "Aqu\u00ed vamos a utilizar la opci\u00f3n Non que", "start": 1054.96, "duration": 4.56}, {"text": "es la detecci\u00f3n autom\u00e1tica el dtype se", "start": 1056.96, "duration": 4.079}, {"text": "refiere al tipo de datos que se va a", "start": 1059.52, "duration": 3.159}, {"text": "utilizar para representar los n\u00fameros", "start": 1061.039, "duration": 4.241}, {"text": "del modelo no Y esto es importante como", "start": 1062.679, "duration": 3.88}, {"text": "hemos visto anteriormente cuando", "start": 1065.28, "duration": 2.84}, {"text": "hablamos de la cuantizaci\u00f3n porque esto", "start": 1066.559, "duration": 3.36}, {"text": "afecta la precisi\u00f3n de los c\u00e1lculos el", "start": 1068.12, "duration": 3.16}, {"text": "uso de la memoria y la velocidad de", "start": 1069.919, "duration": 3.441}, {"text": "procesamiento la disponibilidad de los", "start": 1071.28, "duration": 4.519}, {"text": "par\u00e1metros puede depender de la tarjeta", "start": 1073.36, "duration": 4.799}, {"text": "gr\u00e1fica que utilizamos aqu\u00ed os dejo pues", "start": 1075.799, "duration": 3.601}, {"text": "alguna", "start": 1078.159, "duration": 4.561}, {"text": "por ejemplo en el caso de bflow 16 solo", "start": 1079.4, "duration": 5.36}, {"text": "es posible utilizarlas para gpus con", "start": 1082.72, "duration": 5.28}, {"text": "arquitectura ampere y m\u00e1s recientes por", "start": 1084.76, "duration": 4.6}, {"text": "lo tanto Siempre os aconsejo este", "start": 1088.0, "duration": 2.96}, {"text": "par\u00e1metro si no estamos seguros dejarlo", "start": 1089.36, "duration": 3.799}, {"text": "en N y nos har\u00e1 una detecci\u00f3n autom\u00e1tica", "start": 1090.96, "duration": 4.24}, {"text": "y escoger\u00e1 la opci\u00f3n m\u00e1s conveniente", "start": 1093.159, "duration": 4.76}, {"text": "para nosotros vale lo \u00faltimo tambi\u00e9n", "start": 1095.2, "duration": 5.44}, {"text": "aqu\u00ed tenemos este par\u00e1metro el load in 4", "start": 1097.919, "duration": 5.161}, {"text": "bit y b\u00e1sicamente esto activa la", "start": 1100.64, "duration": 4.159}, {"text": "cuantizaci\u00f3n de 4 bits para ahorrar", "start": 1103.08, "duration": 3.92}, {"text": "memoria como hemos dicho al final la", "start": 1104.799, "duration": 4.601}, {"text": "t\u00e9cnica vamos a utilizar es k esto es", "start": 1107.0, "duration": 4.6}, {"text": "opcional puede ser false si no lo", "start": 1109.4, "duration": 4.96}, {"text": "queremos y Bueno luego por \u00faltimo", "start": 1111.6, "duration": 5.68}, {"text": "tambi\u00e9n mencionar que en este caso estoy", "start": 1114.36, "duration": 6.28}, {"text": "cogiendo el un una versi\u00f3n de Lama 3.1", "start": 1117.28, "duration": 6.759}, {"text": "pre cuantizada a 4 bits debido a que es", "start": 1120.64, "duration": 5.24}, {"text": "mucho m\u00e1s ligera de Descargar la versi\u00f3n", "start": 1124.039, "duration": 4.161}, {"text": "original de 16 bits son 16 Gb y esta", "start": 1125.88, "duration": 4.919}, {"text": "versi\u00f3n son 5,4 por lo tanto como", "start": 1128.2, "duration": 4.599}, {"text": "estamos en entornos restringidos estamos", "start": 1130.799, "duration": 4.24}, {"text": "mirando ahorrar al m\u00e1ximo descargamos", "start": 1132.799, "duration": 3.12}, {"text": "esta", "start": 1135.039, "duration": 3.921}, {"text": "versi\u00f3n vale estos son los par\u00e1metros", "start": 1135.919, "duration": 5.281}, {"text": "utilizamos la clase de fast lingu watch", "start": 1138.96, "duration": 5.079}, {"text": "model from pretrain que hemos importado", "start": 1141.2, "duration": 4.719}, {"text": "aqu\u00ed", "start": 1144.039, "duration": 4.76}, {"text": "arriba y nos descargamos el modelo aqu\u00ed", "start": 1145.919, "duration": 4.801}, {"text": "hace bueno todo el proceso de descarga", "start": 1148.799, "duration": 4.921}, {"text": "como podemos comprobar y a continuaci\u00f3n", "start": 1150.72, "duration": 4.92}, {"text": "lo que vamos a hacer es preparar lo que", "start": 1153.72, "duration": 4.16}, {"text": "va a ser nuestro par\u00e1metro de Fish and", "start": 1155.64, "duration": 5.039}, {"text": "fine tuning otra vez aqu\u00ed ten\u00e9is en", "start": 1157.88, "duration": 4.88}, {"text": "detalle todo explicado todos los", "start": 1160.679, "duration": 4.401}, {"text": "par\u00e1metros que podemos ver aqu\u00ed me voy a", "start": 1162.76, "duration": 4.919}, {"text": "parar en los m\u00e1s importantes que son", "start": 1165.08, "duration": 4.2}, {"text": "estos de aqu\u00ed al final cuando entramos", "start": 1167.679, "duration": 3.201}, {"text": "dentro cuando estamos dentro de las", "start": 1169.28, "duration": 4.16}, {"text": "t\u00e9cnicas Lora queora final hay tres", "start": 1170.88, "duration": 4.159}, {"text": "par\u00e1metros", "start": 1173.44, "duration": 3.96}, {"text": "fundamentales el primero de ellos es el", "start": 1175.039, "duration": 4.64}, {"text": "rango que este valor determina el tama\u00f1o", "start": 1177.4, "duration": 3.759}, {"text": "de las matrices del hora o sea", "start": 1179.679, "duration": 2.841}, {"text": "normalmente se empieza con un Rango de", "start": 1181.159, "duration": 4.601}, {"text": "8o Pero puede llegar hasta 256 siempre", "start": 1182.52, "duration": 5.56}, {"text": "siguiendo normalmente los m\u00faltiplos de", "start": 1185.76, "duration": 5.64}, {"text": "8o no es decir 8 16 etc\u00e9tera etc\u00e9tera un", "start": 1188.08, "duration": 4.92}, {"text": "Rango mayor permite almacenar m\u00e1s", "start": 1191.4, "duration": 4.32}, {"text": "informaci\u00f3n pero tambi\u00e9n obviamente todo", "start": 1193.0, "duration": 4.32}, {"text": "esto siempre va en detrimento de El", "start": 1195.72, "duration": 3.439}, {"text": "coste computacional y de memoria", "start": 1197.32, "duration": 3.479}, {"text": "Entonces en este caso hemos optado por", "start": 1199.159, "duration": 4.481}, {"text": "un valor de 16 un valor Modesto luego", "start": 1200.799, "duration": 5.88}, {"text": "tenemos Alfa olor a Alfa que es el", "start": 1203.64, "duration": 4.24}, {"text": "factor de escala para las", "start": 1206.679, "duration": 3.0}, {"text": "actualizaciones no esto influye", "start": 1207.88, "duration": 3.88}, {"text": "directamente en cu\u00e1nto contribuyen los", "start": 1209.679, "duration": 4.081}, {"text": "adaptadores controla la magnitud de la", "start": 1211.76, "duration": 4.44}, {"text": "contribuci\u00f3n de los adaptadores Lora a", "start": 1213.76, "duration": 4.88}, {"text": "la red principal como hemos dicho aqu\u00ed", "start": 1216.2, "duration": 4.12}, {"text": "no estamos entrenando directamente los", "start": 1218.64, "duration": 4.039}, {"text": "par\u00e1metros estos los congelamos y lo que", "start": 1220.32, "duration": 5.04}, {"text": "hacemos Es crear unos adaptadores y el", "start": 1222.679, "duration": 4.161}, {"text": "valor de Alfa influye en el", "start": 1225.36, "duration": 3.799}, {"text": "comportamiento de estos adaptadores en", "start": 1226.84, "duration": 4.12}, {"text": "cuanto influyen a estos par\u00e1metros que", "start": 1229.159, "duration": 4.64}, {"text": "hemos congelado entonces Lora Alfa", "start": 1230.96, "duration": 4.959}, {"text": "normalmente suele establecerse como uno", "start": 1233.799, "duration": 4.201}, {"text": "o dos veces el rango en este caso hemos", "start": 1235.919, "duration": 4.961}, {"text": "optado por una vez el rango es decir 1", "start": 1238.0, "duration": 5.96}, {"text": "por r hemos optado por un un Rango de 16", "start": 1240.88, "duration": 5.56}, {"text": "por lo tanto el orden de magnitud en", "start": 1243.96, "duration": 3.76}, {"text": "este caso es de uno por lo tanto lo", "start": 1246.44, "duration": 5.479}, {"text": "mantenemos tambi\u00e9n Lora Alfa en 16 y", "start": 1247.72, "duration": 6.72}, {"text": "luego por \u00faltimo los Target modules que", "start": 1251.919, "duration": 5.401}, {"text": "es esto que veis aqu\u00ed no esta esta lista", "start": 1254.44, "duration": 6.56}, {"text": "de strings Lora se puede aplicar a", "start": 1257.32, "duration": 5.479}, {"text": "varios componentes del modelo no como", "start": 1261.0, "duration": 3.679}, {"text": "son los mecanismos de atenci\u00f3n que son", "start": 1262.799, "duration": 4.681}, {"text": "las matrices kqv las proyecciones de", "start": 1264.679, "duration": 5.321}, {"text": "salida los bloes fit Forward y capas", "start": 1267.48, "duration": 5.52}, {"text": "lineales de salida esto qu\u00e9 quiere decir", "start": 1270.0, "duration": 5.24}, {"text": "si no suena De nada a grosso modo", "start": 1273.0, "duration": 3.96}, {"text": "b\u00e1sicamente lo que estamos haciendo como", "start": 1275.24, "duration": 4.0}, {"text": "he dicho antes es tratar o trabajar con", "start": 1276.96, "duration": 4.48}, {"text": "un modelo de Deep learning dentro de las", "start": 1279.24, "duration": 4.64}, {"text": "arquitecturas de Deep learning Existen", "start": 1281.44, "duration": 4.4}, {"text": "algunas complejas no como son las", "start": 1283.88, "duration": 4.76}, {"text": "Transformers al final estas", "start": 1285.84, "duration": 5.6}, {"text": "arquitecturas tienen diferentes capas", "start": 1288.64, "duration": 4.2}, {"text": "diferentes partes o sea hay", "start": 1291.44, "duration": 2.839}, {"text": "arquitecturas que se pueden combinar", "start": 1292.84, "duration": 3.719}, {"text": "entre s\u00ed y normalmente en estos modelos", "start": 1294.279, "duration": 4.4}, {"text": "tan complejos se suele hacer entonces", "start": 1296.559, "duration": 4.521}, {"text": "con los Target moduls podemos controlar", "start": 1298.679, "duration": 4.88}, {"text": "d\u00f3nde vamos a aplicar toda esta", "start": 1301.08, "duration": 4.76}, {"text": "adaptaci\u00f3n entonces Bueno aqu\u00ed nos dice", "start": 1303.559, "duration": 4.12}, {"text": "que aunque inicialmente se centra en los", "start": 1305.84, "duration": 4.28}, {"text": "mecanismos de atenci\u00f3n expandirlo ahora", "start": 1307.679, "duration": 4.24}, {"text": "a otros componentes ha demostrado que es", "start": 1310.12, "duration": 3.84}, {"text": "beneficioso por eso pues tenemos este", "start": 1311.919, "duration": 4.401}, {"text": "control de decidir A qu\u00e9 componentes", "start": 1313.96, "duration": 5.36}, {"text": "queremos afectar sin embargo adaptar m\u00e1s", "start": 1316.32, "duration": 4.56}, {"text": "m\u00f3dulos implica un aumento del n\u00famero de", "start": 1319.32, "duration": 4.0}, {"text": "par\u00e1metros entrenables y las necesidades", "start": 1320.88, "duration": 4.279}, {"text": "de memoria Entonces en este caso hemos", "start": 1323.32, "duration": 3.8}, {"text": "decidido aplicarlo orora todos los", "start": 1325.159, "duration": 4.4}, {"text": "m\u00f3dulos lineales para maximizar la", "start": 1327.12, "duration": 4.4}, {"text": "calidad Es verdad que todo lo que hemos", "start": 1329.559, "duration": 4.24}, {"text": "visto hasta ahora hemos intentado ahrar", "start": 1331.52, "duration": 4.279}, {"text": "al m\u00e1ximo Aqu\u00ed s\u00ed que igual vale la pena", "start": 1333.799, "duration": 4.601}, {"text": "no escatimar tanto para como decimos", "start": 1335.799, "duration": 4.081}, {"text": "pues maximizar la calidad de las", "start": 1338.4, "duration": 2.8}, {"text": "predicciones que vamos a conseguir", "start": 1339.88, "duration": 3.159}, {"text": "despu\u00e9s vale luego Aqu\u00ed ten\u00e9is otros", "start": 1341.2, "duration": 4.32}, {"text": "par\u00e1metros que para este caso son", "start": 1343.039, "duration": 4.841}, {"text": "secundarios no los voy a comentar todos", "start": 1345.52, "duration": 5.2}, {"text": "eh eh Pero bueno por ejemplo dropout es", "start": 1347.88, "duration": 4.72}, {"text": "una t\u00e9cnica de regularizaci\u00f3n", "start": 1350.72, "duration": 3.72}, {"text": "b\u00e1sicamente que esto las t\u00e9cnicas de", "start": 1352.6, "duration": 3.4}, {"text": "regularizaci\u00f3n Normalmente se utilizan", "start": 1354.44, "duration": 3.719}, {"text": "para prevenir el el", "start": 1356.0, "duration": 5.24}, {"text": "overfitting y la t\u00e9cnica dropout Hay", "start": 1358.159, "duration": 5.321}, {"text": "much\u00edsimas pero esta en concreto eh", "start": 1361.24, "duration": 4.52}, {"text": "consiste en que aleatoriamente se", "start": 1363.48, "duration": 4.0}, {"text": "desactivan Pues un porcentaje de", "start": 1365.76, "duration": 3.64}, {"text": "conexiones en este caso estamos hablando", "start": 1367.48, "duration": 3.48}, {"text": "de las conexiones de las matrices de", "start": 1369.4, "duration": 4.08}, {"text": "adaptaci\u00f3n durante el entrenamiento no", "start": 1370.96, "duration": 4.4}, {"text": "como bueno vemos aqu\u00ed he dicho antes", "start": 1373.48, "duration": 3.36}, {"text": "Esto es lo que intenta prevenir es el", "start": 1375.36, "duration": 3.679}, {"text": "sobreajuste el overfitting", "start": 1376.84, "duration": 4.04}, {"text": "y bueno Esto tambi\u00e9n ralentiza", "start": 1379.039, "duration": 3.841}, {"text": "ligeramente el entrenamiento por lo que", "start": 1380.88, "duration": 3.96}, {"text": "en este caso tambi\u00e9n vamos a optar por", "start": 1382.88, "duration": 4.919}, {"text": "no usarlo no me voy a extender al final", "start": 1384.84, "duration": 4.88}, {"text": "pod\u00e9is aqu\u00ed leer en en detalle lo que", "start": 1387.799, "duration": 4.601}, {"text": "ser\u00eda el RS cula el gradient checkpoint", "start": 1389.72, "duration": 6.48}, {"text": "que al final es poco importante ten\u00e9is", "start": 1392.4, "duration": 5.56}, {"text": "aqu\u00ed Toda la descripci\u00f3n en detalle", "start": 1396.2, "duration": 3.4}, {"text": "entonces aqu\u00ed es lo que estamos haciendo", "start": 1397.96, "duration": 4.04}, {"text": "No preparar lo que va a ser nuestro", "start": 1399.6, "duration": 4.76}, {"text": "proceso de entrenamiento con todos estos", "start": 1402.0, "duration": 4.24}, {"text": "par\u00e1metros que ten\u00e9is aqu\u00ed detallados", "start": 1404.36, "duration": 4.199}, {"text": "otra vez lo siguiente es preparar", "start": 1406.24, "duration": 5.96}, {"text": "nuestro dataset y nuestro tokenizador al", "start": 1408.559, "duration": 6.48}, {"text": "final vamos a utilizar un chat template", "start": 1412.2, "duration": 5.839}, {"text": "esta funci\u00f3n aqu\u00ed la hemos importado", "start": 1415.039, "duration": 5.921}, {"text": "previamente como podemos ver aqu\u00ed nos la", "start": 1418.039, "duration": 5.361}, {"text": "proporciona la libida de ansol tambi\u00e9n", "start": 1420.96, "duration": 5.28}, {"text": "que chat template le pasamos el", "start": 1423.4, "duration": 6.48}, {"text": "tokenizador luego el tipo de mapeo ya", "start": 1426.24, "duration": 5.16}, {"text": "esto tambi\u00e9n es bastante com\u00fan los que", "start": 1429.88, "duration": 3.0}, {"text": "est\u00e1is acostumbrados a trabajar con", "start": 1431.4, "duration": 3.92}, {"text": "modelos de chat al final pues tenemos el", "start": 1432.88, "duration": 5.56}, {"text": "lo que ser\u00eda el roll un System prom eh", "start": 1435.32, "duration": 5.2}, {"text": "el el valor del usuario etc\u00e9tera", "start": 1438.44, "duration": 5.2}, {"text": "etc\u00e9tera al final Aqu\u00ed hacemos un mapeo", "start": 1440.52, "duration": 5.88}, {"text": "de todo esto en cuanto al chat template", "start": 1443.64, "duration": 5.68}, {"text": "y le decimos que chat template vamos a", "start": 1446.4, "duration": 5.96}, {"text": "utilizar Entonces nos lo descargamos en", "start": 1449.32, "duration": 5.92}, {"text": "este caso el dataset que voy a utilizar", "start": 1452.36, "duration": 5.799}, {"text": "es Gracias y damos cr\u00e9ditos a maxim", "start": 1455.24, "duration": 6.48}, {"text": "lab\u00f3n que esto es un un dataset bastante", "start": 1458.159, "duration": 6.481}, {"text": "refinado que se llama fantom 100k", "start": 1461.72, "duration": 6.079}, {"text": "utiliza el formato de del dataset share", "start": 1464.64, "duration": 4.279}, {"text": "gpt", "start": 1467.799, "duration": 2.921}, {"text": "que es ideal para conversaciones", "start": 1468.919, "duration": 3.48}, {"text": "multiturn no al final pues para una", "start": 1470.72, "duration": 4.16}, {"text": "conversaci\u00f3n de chat natural y este", "start": 1472.399, "duration": 4.28}, {"text": "bueno como nos dice aqu\u00ed este formato se", "start": 1474.88, "duration": 3.2}, {"text": "procesa para extraer pares de", "start": 1476.679, "duration": 4.36}, {"text": "instrucci\u00f3n respuesta luego los datos se", "start": 1478.08, "duration": 4.92}, {"text": "reformate seg\u00fan una plantilla de chat", "start": 1481.039, "duration": 4.12}, {"text": "como chat emel que es lo que lo que", "start": 1483.0, "duration": 3.96}, {"text": "hemos hecho arriba que estructura la", "start": 1485.159, "duration": 3.64}, {"text": "conversaci\u00f3n no chatel usa tokens", "start": 1486.96, "duration": 3.599}, {"text": "especiales para marcar el inicio y el", "start": 1488.799, "duration": 3.201}, {"text": "fin de cada", "start": 1490.559, "duration": 4.561}, {"text": "mensaje que aqu\u00ed lo", "start": 1492.0, "duration": 5.72}, {"text": "ten\u00e9is estos son los par\u00e1metros de", "start": 1495.12, "duration": 4.799}, {"text": "inicio y final luego lo veremos en la", "start": 1497.72, "duration": 5.16}, {"text": "respuesta tambi\u00e9n pues al final esto es", "start": 1499.919, "duration": 5.88}, {"text": "un dataset s super refinado de much\u00edsima", "start": 1502.88, "duration": 5.48}, {"text": "calidad gracias a maxim labon vale lo", "start": 1505.799, "duration": 4.161}, {"text": "siguiente b\u00e1sicamente es una funci\u00f3n", "start": 1508.36, "duration": 5.199}, {"text": "para aplicar este template al al dataset", "start": 1509.96, "duration": 6.16}, {"text": "al final cogemos los ejemplos aplicamos", "start": 1513.559, "duration": 4.881}, {"text": "tokenizador o sea con el tokenizador", "start": 1516.12, "duration": 4.559}, {"text": "aplicamos el chat template que hemos", "start": 1518.44, "duration": 4.56}, {"text": "generado anteriormente Y devolvemos el", "start": 1520.679, "duration": 5.201}, {"text": "texto finalmente ya tenemos aqu\u00ed nuestro", "start": 1523.0, "duration": 5.84}, {"text": "template aplicado Ahora nos toca toca", "start": 1525.88, "duration": 7.0}, {"text": "Descargar el dataset vamos a hacer el", "start": 1528.84, "duration": 6.24}, {"text": "Split normalmente los datasets se suele", "start": 1532.88, "duration": 4.12}, {"text": "para poder comprobar el la cura si se", "start": 1535.08, "duration": 4.479}, {"text": "suele hacer una peque\u00f1a divisi\u00f3n un gran", "start": 1537.0, "duration": 4.679}, {"text": "porcentaje normalmente suele estar en", "start": 1539.559, "duration": 5.321}, {"text": "torno al 70 80% del porcentaje del", "start": 1541.679, "duration": 5.36}, {"text": "dataset va a ser para entrenamiento y el", "start": 1544.88, "duration": 4.64}, {"text": "otro pues para comprobar esa efectividad", "start": 1547.039, "duration": 5.561}, {"text": "y prevenir el El overfitting Bueno pues", "start": 1549.52, "duration": 4.96}, {"text": "aqu\u00ed ya nos descargamos el dataset", "start": 1552.6, "duration": 4.64}, {"text": "aplicamos nuestro template de manera", "start": 1554.48, "duration": 4.88}, {"text": "bache al final vemos aqu\u00ed todo el", "start": 1557.24, "duration": 5.559}, {"text": "proceso y ya lo que nos quedar\u00eda es", "start": 1559.36, "duration": 6.08}, {"text": "preparar todo lo que va a ser nuestra", "start": 1562.799, "duration": 5.401}, {"text": "fase de entrenamiento aqu\u00ed como vemos", "start": 1565.44, "duration": 4.119}, {"text": "aqu\u00ed s\u00ed que hay una cantidad de", "start": 1568.2, "duration": 2.32}, {"text": "par\u00e1metros", "start": 1569.559, "duration": 3.12}, {"text": "importantes no me voy a detener a", "start": 1570.52, "duration": 4.68}, {"text": "explicarlos porque si no el v\u00eddeo se va", "start": 1572.679, "duration": 5.161}, {"text": "a alargar demasiado As\u00ed que como ya", "start": 1575.2, "duration": 5.04}, {"text": "sab\u00e9is lo ten\u00e9is aqu\u00ed de manera super", "start": 1577.84, "duration": 4.48}, {"text": "detallada s\u00ed que voy a mencionar dos que", "start": 1580.24, "duration": 3.84}, {"text": "quiz\u00e1s y que los necesitamos para", "start": 1582.32, "duration": 3.88}, {"text": "entender todo esto que va a pasar por un", "start": 1584.08, "duration": 4.28}, {"text": "lado es el learning rate que es la tasa", "start": 1586.2, "duration": 3.64}, {"text": "aprendizaje que esto controla la", "start": 1588.36, "duration": 3.08}, {"text": "intensidad de las actualizaciones es", "start": 1589.84, "duration": 4.76}, {"text": "decir el tama\u00f1o eh de los pasos de los", "start": 1591.44, "duration": 5.68}, {"text": "par\u00e1metros esto debe equilibrarse no", "start": 1594.6, "duration": 4.72}, {"text": "para evitar un aprendizaje lento o", "start": 1597.12, "duration": 4.559}, {"text": "inestable Entonces en este caso pues", "start": 1599.32, "duration": 5.32}, {"text": "vamos a utilizar", "start": 1601.679, "duration": 2.961}, {"text": "0,0003 es decir al final es un learning", "start": 1604.88, "duration": 4.88}, {"text": "rate bastante peque\u00f1ito una tasa de", "start": 1607.679, "duration": 4.88}, {"text": "aprendizaje bastante peque\u00f1a para", "start": 1609.76, "duration": 5.44}, {"text": "intentar conseguir la mayor estabilidad", "start": 1612.559, "duration": 6.081}, {"text": "luego el siguiente es el n\u00famero de \u00e9poca", "start": 1615.2, "duration": 5.16}, {"text": "el n\u00famero de \u00e9pocas es la cantidad de", "start": 1618.64, "duration": 3.68}, {"text": "veces que va el modelo a recorrer todo", "start": 1620.36, "duration": 4.84}, {"text": "el dataset en este caso vamos a utilizar", "start": 1622.32, "duration": 5.68}, {"text": "uno porque es m\u00e1s que suficiente o sea", "start": 1625.2, "duration": 4.0}, {"text": "es decir si estuvi\u00e9semos haciendo un", "start": 1628.0, "duration": 3.279}, {"text": "full fine tuning seguramente", "start": 1629.2, "duration": 4.28}, {"text": "necesitar\u00edamos much\u00edsimas m\u00e1s no ser\u00eda", "start": 1631.279, "duration": 4.561}, {"text": "suficiente con una en este caso como", "start": 1633.48, "duration": 5.04}, {"text": "estamos haciendo un fine tuning mediante", "start": 1635.84, "duration": 5.6}, {"text": "Lora en el cual Pues todo el lo que es", "start": 1638.52, "duration": 4.68}, {"text": "el conocimiento del modelo lo vamos a", "start": 1641.44, "duration": 3.52}, {"text": "mantener y lo \u00fanico que vamos a hacer es", "start": 1643.2, "duration": 4.04}, {"text": "darle esta peque\u00f1a especializaci\u00f3n con", "start": 1644.96, "duration": 5.0}, {"text": "un Step es suficiente Adem\u00e1s ya veis el", "start": 1647.24, "duration": 4.96}, {"text": "proceso ahora os lo ense\u00f1ar\u00e9 dura", "start": 1649.96, "duration": 5.28}, {"text": "bastante cuantas m\u00e1s \u00e9pocas le a\u00f1adamos", "start": 1652.2, "duration": 5.959}, {"text": "pues este proceso pues va va a empezar a", "start": 1655.24, "duration": 4.84}, {"text": "multiplicarse Bueno entonces aqu\u00ed pues", "start": 1658.159, "duration": 3.76}, {"text": "preparamos nuestro entrenador nuestro", "start": 1660.08, "duration": 4.12}, {"text": "trainer con todos los par\u00e1metros los", "start": 1661.919, "duration": 4.521}, {"text": "ten\u00e9is aqu\u00ed detalladamente explicados", "start": 1664.2, "duration": 4.839}, {"text": "todos los que vamos a utilizar Y por", "start": 1666.44, "duration": 5.719}, {"text": "\u00faltimo ya con nuestro trainer preparado", "start": 1669.039, "duration": 4.48}, {"text": "con todos los par\u00e1metros que hemos", "start": 1672.159, "duration": 3.4}, {"text": "escogido no nos queda otra que llamar a", "start": 1673.519, "duration": 5.121}, {"text": "la funci\u00f3n train y empezar esta fase de", "start": 1675.559, "duration": 5.321}, {"text": "entrenamiento vale como vemos aqu\u00ed aqu\u00ed", "start": 1678.64, "duration": 5.84}, {"text": "nos dice el paso por el que va y la", "start": 1680.88, "duration": 5.799}, {"text": "p\u00e9rdida la intenci\u00f3n del entrenamiento", "start": 1684.48, "duration": 5.28}, {"text": "obviamente es minimizar la p\u00e9rdida No", "start": 1686.679, "duration": 5.12}, {"text": "aqu\u00ed nos da un resumen de todo lo que va", "start": 1689.76, "duration": 3.799}, {"text": "a suceder el n\u00famero de ejemplos que", "start": 1691.799, "duration": 3.401}, {"text": "tenemos el n\u00famero de \u00e9pocas que hemos", "start": 1693.559, "duration": 4.161}, {"text": "escogido el n\u00famero de gpus etc\u00e9tera", "start": 1695.2, "duration": 4.52}, {"text": "etc\u00e9tera Pero bueno aqu\u00ed importante es", "start": 1697.72, "duration": 4.839}, {"text": "el total de pasos que va a necesitar que", "start": 1699.72, "duration": 7.4}, {"text": "son 1813 pasos", "start": 1702.559, "duration": 8.081}, {"text": "1813 que b\u00e1sicamente esto Pues ser\u00e1 los", "start": 1707.12, "duration": 5.72}, {"text": "29,000 divido entre 16 nos da el total", "start": 1710.64, "duration": 4.32}, {"text": "de pasos ya que los los batch de cada", "start": 1712.84, "duration": 5.28}, {"text": "paso son de eh 16 y aqu\u00ed nos dice en", "start": 1714.96, "duration": 5.439}, {"text": "total Cu\u00e1l va a ser el n\u00famero entrenable", "start": 1718.12, "duration": 5.36}, {"text": "de par\u00e1metros con esto Esto se me ha", "start": 1720.399, "duration": 5.841}, {"text": "olvidado comentar que he dejado un", "start": 1723.48, "duration": 3.88}, {"text": "comentario aqu\u00ed no que con esta", "start": 1726.24, "duration": 2.88}, {"text": "configuraci\u00f3n del hora Total que hemos", "start": 1727.36, "duration": 4.76}, {"text": "hecho estaremos entrenando solamente 42", "start": 1729.12, "duration": 4.679}, {"text": "millones de par\u00e1metros de un total de", "start": 1732.12, "duration": 4.88}, {"text": "8000 millones 8 billions 8 billions que", "start": 1733.799, "duration": 5.401}, {"text": "tiene el modelo lo que representa apenas", "start": 1737.0, "duration": 3.12}, {"text": "un", "start": 1739.2, "duration": 4.04}, {"text": "0,52 por no O sea por lo tanto supone un", "start": 1740.12, "duration": 5.2}, {"text": "ahorro considerable en cuanto a recursos", "start": 1743.24, "duration": 4.52}, {"text": "computacionales y de tiempo o imaginaos", "start": 1745.32, "duration": 5.76}, {"text": "si con este proceso que ha tardado casi", "start": 1747.76, "duration": 6.0}, {"text": "5 horas 4 horas 40 y pico minutos si no", "start": 1751.08, "duration": 4.8}, {"text": "me equivoco imaginaos si tuvi\u00e9ramos que", "start": 1753.76, "duration": 4.279}, {"text": "hacer un full fine tuning realmente es", "start": 1755.88, "duration": 4.279}, {"text": "muy muy muy costoso bueno pues aqu\u00ed", "start": 1758.039, "duration": 4.281}, {"text": "podemos comprobar todos los steps como", "start": 1760.159, "duration": 5.4}, {"text": "veis Aqu\u00ed bueno en este snapshot hab\u00edan", "start": 1762.32, "duration": 5.76}, {"text": "pasado 42 minutos y pon\u00eda que Leal", "start": 1765.559, "duration": 4.72}, {"text": "faltaba 4 horas 7 minutos o sea", "start": 1768.08, "duration": 5.479}, {"text": "pr\u00e1cticamente Son 5 horas aqu\u00ed veis todo", "start": 1770.279, "duration": 6.081}, {"text": "el proceso podemos ver comoo va bajando", "start": 1773.559, "duration": 6.0}, {"text": "el la p\u00e9rdida el training loss Es normal", "start": 1776.36, "duration": 5.159}, {"text": "que en algunos pasos suba no al final de", "start": 1779.559, "duration": 3.72}, {"text": "Esto va tambi\u00e9n el learning rate al", "start": 1781.519, "duration": 3.16}, {"text": "final prueba dar un paso en una", "start": 1783.279, "duration": 4.041}, {"text": "direcci\u00f3n eh si ve que sube pues coge", "start": 1784.679, "duration": 5.48}, {"text": "otra direcci\u00f3n y va bajando el el global", "start": 1787.32, "duration": 5.359}, {"text": "como vemos empezamos con un y pico y al", "start": 1790.159, "duration": 4.921}, {"text": "final a lo largo de los diferentes pasos", "start": 1792.679, "duration": 4.12}, {"text": "va disminuyendo esto es que ha habido", "start": 1795.08, "duration": 4.0}, {"text": "aqu\u00ed una peque\u00f1a interrupci\u00f3n eh Por eso", "start": 1796.799, "duration": 5.561}, {"text": "vuelve a salir aqu\u00ed esta barra vamos a", "start": 1799.08, "duration": 5.28}, {"text": "ver hasta los pasos finales C\u00f3mo ha", "start": 1802.36, "duration": 5.24}, {"text": "terminado la p\u00e9rdida finalmente vale", "start": 1804.36, "duration": 4.88}, {"text": "Aqu\u00ed vemos que en El Paso ya final que", "start": 1807.6, "duration": 4.76}, {"text": "es el 1813 tenemos una p\u00e9rdida de", "start": 1809.24, "duration": 8.0}, {"text": "0.58 0.59 si redondeamos del 1.18 si no", "start": 1812.36, "duration": 6.76}, {"text": "recuerdo mal por el cual hab\u00edamos", "start": 1817.24, "duration": 4.08}, {"text": "empezado Pues bien como os digo esto ha", "start": 1819.12, "duration": 5.919}, {"text": "tardado pr\u00e1cticamente casi 5 horas es", "start": 1821.32, "duration": 5.32}, {"text": "por esto como os mencionaba", "start": 1825.039, "duration": 3.48}, {"text": "anteriormente que he decidido", "start": 1826.64, "duration": 4.919}, {"text": "para este v\u00eddeo pagar colap Pro Plus", "start": 1828.519, "duration": 5.16}, {"text": "porque el plan de colap Pro Plus que es", "start": 1831.559, "duration": 4.24}, {"text": "bastante Caro La verdad no no lo", "start": 1833.679, "duration": 4.201}, {"text": "recomiendo Pero es el \u00fanico que nos", "start": 1835.799, "duration": 3.76}, {"text": "permite la ejecuci\u00f3n en background esto", "start": 1837.88, "duration": 3.6}, {"text": "que quiere decir que si yo cierro el", "start": 1839.559, "duration": 4.401}, {"text": "ordenador el navegador el proceso de", "start": 1841.48, "duration": 4.4}, {"text": "ejecuci\u00f3n de este Notebook Va a", "start": 1843.96, "duration": 4.4}, {"text": "continuar Entonces como no ten\u00eda 5 horas", "start": 1845.88, "duration": 5.08}, {"text": "para estar controlando el proceso Pues", "start": 1848.36, "duration": 5.76}, {"text": "he decidido pagar el prop Plus pero como", "start": 1850.96, "duration": 4.76}, {"text": "digo no os lo aconsejo porque realmente", "start": 1854.12, "duration": 4.64}, {"text": "col la app es bastante inestable y a\u00fan", "start": 1855.72, "duration": 5.48}, {"text": "habiendo pagado se me ha interrumpido la", "start": 1858.76, "duration": 4.44}, {"text": "el proceso un par de veces y he tenido", "start": 1861.2, "duration": 4.76}, {"text": "que volver a empezar por lo tanto eh No", "start": 1863.2, "duration": 5.719}, {"text": "lo aconsejo es posible como dec\u00eda en el", "start": 1865.96, "duration": 5.199}, {"text": "v\u00eddeo entrenar de manera totalmente", "start": 1868.919, "duration": 5.201}, {"text": "gratuita el modelo obviamente es posible", "start": 1871.159, "duration": 5.52}, {"text": "lo que no vamos a tener disponibles son", "start": 1874.12, "duration": 4.48}, {"text": "pues las gpus m\u00e1s potentes que en este", "start": 1876.679, "duration": 5.521}, {"text": "caso he utilizado una nvidia a100 vamos", "start": 1878.6, "duration": 7.28}, {"text": "a tener gpus mucho menos potentes con", "start": 1882.2, "duration": 5.28}, {"text": "mucha menos memoria por lo tanto el", "start": 1885.88, "duration": 4.279}, {"text": "entren amento se nos puede ir pues", "start": 1887.48, "duration": 5.199}, {"text": "a tranquilamente Bueno m\u00e1s de un d\u00eda", "start": 1890.159, "duration": 5.601}, {"text": "seguro posiblemente cerca de dos d\u00edas", "start": 1892.679, "duration": 6.081}, {"text": "Por eso bueno es posible si ten\u00e9is ese", "start": 1895.76, "duration": 4.56}, {"text": "tiempo para ir de tanto en tanto", "start": 1898.76, "duration": 3.039}, {"text": "controlando que la ejecuci\u00f3n no se pare", "start": 1900.32, "duration": 3.16}, {"text": "que el Notebook no se cierre etc\u00e9tera", "start": 1901.799, "duration": 3.281}, {"text": "etc\u00e9tera pues Ser\u00eda posible hacerlo de", "start": 1903.48, "duration": 4.079}, {"text": "manera totalmente gratuita sin ning\u00fan", "start": 1905.08, "duration": 4.599}, {"text": "problema colap permite otra opci\u00f3n que", "start": 1907.559, "duration": 4.401}, {"text": "es de comprar cr\u00e9ditos bajo demanda lo", "start": 1909.679, "duration": 3.88}, {"text": "cual no os recomiendo porque me ha", "start": 1911.96, "duration": 3.36}, {"text": "pasado tambi\u00e9n lo que hice al principio", "start": 1913.559, "duration": 3.84}, {"text": "fue comprar pues unos pocos cr\u00e9ditos", "start": 1915.32, "duration": 4.44}, {"text": "simplemente para utilizar una gpu", "start": 1917.399, "duration": 5.081}, {"text": "potente como es la a100 y consumir los", "start": 1919.76, "duration": 4.24}, {"text": "solo durante el entrenamiento pero como", "start": 1922.48, "duration": 3.4}, {"text": "no ten\u00eda la ejecuci\u00f3n en background y no", "start": 1924.0, "duration": 3.6}, {"text": "pod\u00eda quedarme delante del ordenador", "start": 1925.88, "duration": 5.399}, {"text": "durante 5 horas en ese momento pues se", "start": 1927.6, "duration": 5.919}, {"text": "me paraba la ejecuci\u00f3n en una de ellas", "start": 1931.279, "duration": 5.0}, {"text": "me sal\u00eda el aviso de bueno que ten\u00edas", "start": 1933.519, "duration": 6.441}, {"text": "que darle por el capcha para asegurarle", "start": 1936.279, "duration": 5.721}, {"text": "que era una persona humana y no un robot", "start": 1939.96, "duration": 3.599}, {"text": "no estaba delante del ordenador y esto", "start": 1942.0, "duration": 3.399}, {"text": "me par\u00f3 la ejecuci\u00f3n Total que consum\u00ed", "start": 1943.559, "duration": 3.521}, {"text": "los cr\u00e9ditos y no pude entrar al modelo", "start": 1945.399, "duration": 3.201}, {"text": "por lo que me tuve que ir al final a", "start": 1947.08, "duration": 4.16}, {"text": "esta opci\u00f3n no os aconsejo comprar", "start": 1948.6, "duration": 5.16}, {"text": "cr\u00e9ditos por separado para esto en tal", "start": 1951.24, "duration": 5.24}, {"text": "caso yo probar\u00eda si ten\u00e9is el tiempo", "start": 1953.76, "duration": 4.919}, {"text": "para dedicarle y estar pendiente probad", "start": 1956.48, "duration": 4.679}, {"text": "con la opci\u00f3n gratuita si no lo", "start": 1958.679, "duration": 4.24}, {"text": "siguiente ser\u00eda la opci\u00f3n de colap Pro", "start": 1961.159, "duration": 4.64}, {"text": "Plus lo que me parece eh un poco cara", "start": 1962.919, "duration": 4.24}, {"text": "para este caso porque no vamos a", "start": 1965.799, "duration": 2.561}, {"text": "aprovechar todos los cr\u00e9ditos", "start": 1967.159, "duration": 2.64}, {"text": "b\u00e1sicamente aqu\u00ed lo interesante es la", "start": 1968.36, "duration": 3.679}, {"text": "ejecuci\u00f3n en background que nos ofrece", "start": 1969.799, "duration": 4.48}, {"text": "realmente comprando unos pocos cr\u00e9ditos", "start": 1972.039, "duration": 4.041}, {"text": "ser\u00eda suficiente para entrenar Este", "start": 1974.279, "duration": 4.161}, {"text": "modelo Pero bueno quer\u00eda", "start": 1976.08, "duration": 3.959}, {"text": "ofreceros este tutorial porque creo que", "start": 1978.44, "duration": 3.68}, {"text": "es muy interesante hay creo que hay", "start": 1980.039, "duration": 4.24}, {"text": "pocos tutoriales en YouTube de habla", "start": 1982.12, "duration": 4.84}, {"text": "hispana o pr\u00e1cticamente ninguno de", "start": 1984.279, "duration": 4.52}, {"text": "calidad para poder hacer fine tuning as\u00ed", "start": 1986.96, "duration": 3.76}, {"text": "que me apetec\u00eda hacer esto por vosotros", "start": 1988.799, "duration": 4.281}, {"text": "y en total Pues a lo mejor han sido unos", "start": 1990.72, "duration": 4.679}, {"text": "70 que me he acabado gastando para poder", "start": 1993.08, "duration": 4.8}, {"text": "entrenar Este modelo cosa que ya os digo", "start": 1995.399, "duration": 4.52}, {"text": "que realmente yo no he gastado poder", "start": 1997.88, "duration": 5.48}, {"text": "computacional de 70 o sea al final me he", "start": 1999.919, "duration": 4.921}, {"text": "desperdiciado muchos cr\u00e9ditos por las", "start": 2003.36, "duration": 3.52}, {"text": "interrupciones y luego al final tambi\u00e9n", "start": 2004.84, "duration": 3.52}, {"text": "me han sobrado muchos cr\u00e9ditos Pero", "start": 2006.88, "duration": 3.919}, {"text": "bueno era la manera m\u00e1s sencilla existen", "start": 2008.36, "duration": 4.08}, {"text": "otras v\u00edas tambi\u00e9n para hacerlo Pero", "start": 2010.799, "duration": 3.88}, {"text": "bueno ya prepar\u00e9 el Notebook De antemano", "start": 2012.44, "duration": 3.52}, {"text": "no sab\u00eda que iba a tener tantos", "start": 2014.679, "duration": 4.641}, {"text": "problemas lo prepar\u00e9 De antemano as\u00ed que", "start": 2015.96, "duration": 4.76}, {"text": "ya prefer\u00eda hacerlo con colap", "start": 2019.32, "duration": 2.88}, {"text": "directamente porque es el notbook que", "start": 2020.72, "duration": 3.12}, {"text": "que os quiero pasar y hacer llegar a", "start": 2022.2, "duration": 4.24}, {"text": "todos vosotros Pues bien sin m\u00e1s no me", "start": 2023.84, "duration": 3.88}, {"text": "enrollo seos he contado todos los", "start": 2026.44, "duration": 2.479}, {"text": "problemas que he tenido Espero que os", "start": 2027.72, "duration": 3.16}, {"text": "sirva de ayuda para que no cometais los", "start": 2028.919, "duration": 4.401}, {"text": "mismos errores que yo y os ahorr\u00e1is un", "start": 2030.88, "duration": 5.08}, {"text": "dinero en el caso de que decid\u00e1is pagar", "start": 2033.32, "duration": 4.92}, {"text": "si no pod\u00e9is explorar otro", "start": 2035.96, "duration": 3.719}, {"text": "servicios", "start": 2038.24, "duration": 3.919}, {"text": "directamente con un Script poder", "start": 2039.679, "duration": 4.24}, {"text": "entrenar el modelo sin necesidad de que", "start": 2042.159, "duration": 3.921}, {"text": "te ofrezcan pues poderlo entrenar desde", "start": 2043.919, "duration": 4.92}, {"text": "un Notebook ser\u00eda una opci\u00f3n muy v\u00e1lida", "start": 2046.08, "duration": 5.68}, {"text": "vale ya tenemos nuestro modelo nuestro", "start": 2048.839, "duration": 6.121}, {"text": "modelo entrenado As\u00ed que utilizando esta", "start": 2051.76, "duration": 5.839}, {"text": "clase que tambi\u00e9n le importamos ansol", "start": 2054.96, "duration": 4.08}, {"text": "esto nos permite esta clase una", "start": 2057.599, "duration": 3.601}, {"text": "inferencia much\u00edsimo m\u00e1s r\u00e1pida por lo", "start": 2059.04, "duration": 4.599}, {"text": "tanto vamos utilizarla ansol tambi\u00e9n", "start": 2061.2, "duration": 5.159}, {"text": "para para la fase de inferencia y nada", "start": 2063.639, "duration": 5.72}, {"text": "aqu\u00ed ya pues definimos nuestro mensaje", "start": 2066.359, "duration": 4.8}, {"text": "le decimos que es este es el mensaje", "start": 2069.359, "duration": 4.28}, {"text": "humano y le hacemos la t\u00edpica pregunta", "start": 2071.159, "duration": 5.96}, {"text": "de que Qu\u00e9 valor es m\u00e1s grande si 9.9 o", "start": 2073.639, "duration": 6.28}, {"text": "9.11 vale lo siguiente este tenemos", "start": 2077.119, "duration": 4.601}, {"text": "bueno estos ser\u00e1n nuestros mensajes", "start": 2079.919, "duration": 4.041}, {"text": "ahora estos inputs los tenemos que", "start": 2081.72, "duration": 6.24}, {"text": "tokenizar y aplicar el el chat template", "start": 2083.96, "duration": 5.32}, {"text": "que hemos utilizado tambi\u00e9n para el", "start": 2087.96, "duration": 4.959}, {"text": "entrenamiento y aqu\u00ed Esto es para poder", "start": 2089.28, "duration": 5.639}, {"text": "una vez tenemos nuestro tokenizador", "start": 2092.919, "duration": 3.841}, {"text": "utilizamos la clase Tex streamer para", "start": 2094.919, "duration": 4.041}, {"text": "que nos streame la respuesta o sea nos", "start": 2096.76, "duration": 3.96}, {"text": "la devuelva en tiempo real mientras se", "start": 2098.96, "duration": 4.0}, {"text": "va generando Y por \u00faltimo Pues en", "start": 2100.72, "duration": 3.92}, {"text": "nuestro modelo utilizamos la funci\u00f3n de", "start": 2102.96, "duration": 4.48}, {"text": "generate le pasamos los inputs que hemos", "start": 2104.64, "duration": 5.04}, {"text": "generado aqu\u00ed ya tokenizados con el chat", "start": 2107.44, "duration": 4.2}, {"text": "template aplicado le pasamos el streamer", "start": 2109.68, "duration": 3.24}, {"text": "que acabamos de crear aqu\u00ed el Tex", "start": 2111.64, "duration": 2.92}, {"text": "streamer el m\u00e1ximo de tokens que", "start": 2112.92, "duration": 3.32}, {"text": "queremos que nos devuelve Y si vamos a", "start": 2114.56, "duration": 4.96}, {"text": "utilizar la cach o no ejecutamos esto y", "start": 2116.24, "duration": 5.2}, {"text": "ya nos devuelve la respuesta como veis", "start": 2119.52, "duration": 4.319}, {"text": "aqu\u00ed utiliza el formato de chat template", "start": 2121.44, "duration": 4.639}, {"text": "como dec\u00edamos que utiliza esta", "start": 2123.839, "duration": 4.321}, {"text": "nomenclatura para ir definiendo los los", "start": 2126.079, "duration": 4.161}, {"text": "siguientes pasos y aqu\u00ed vemos la", "start": 2128.16, "duration": 4.72}, {"text": "respuesta del modelo del asistente nos", "start": 2130.24, "duration": 4.44}, {"text": "da toda la l\u00f3gica y al final aqu\u00ed", "start": 2132.88, "duration": 3.239}, {"text": "tenemos la respuesta final que es", "start": 2134.68, "duration": 4.12}, {"text": "correcta que nos dice que 9.9 es mayor", "start": 2136.119, "duration": 3.361}, {"text": "que", "start": 2138.8, "duration": 3.2}, {"text": "9.11 esta es la cl\u00e1sica pregunta que", "start": 2139.48, "duration": 4.52}, {"text": "muchos modelos hasta hace nada estaban", "start": 2142.0, "duration": 3.72}, {"text": "fallando todav\u00eda algunos a d\u00eda de hoy", "start": 2144.0, "duration": 3.599}, {"text": "siguen fallando en este caso la", "start": 2145.72, "duration": 4.56}, {"text": "respuesta ha sido correcta vale Cu\u00e1l es", "start": 2147.599, "duration": 4.921}, {"text": "el siguiente paso ya para acabar es", "start": 2150.28, "duration": 3.64}, {"text": "guardar nuestro modelo ya que hemos", "start": 2152.52, "duration": 3.079}, {"text": "hecho todo este proceso largo y costoso", "start": 2153.92, "duration": 3.159}, {"text": "ahora queremos guardar nuestro modelo", "start": 2155.599, "duration": 3.48}, {"text": "para poderlo utilizar cuando queramos", "start": 2157.079, "duration": 4.161}, {"text": "entonces aqu\u00ed ten\u00e9is el m\u00e9todo para", "start": 2159.079, "duration": 4.401}, {"text": "guardarlo en local si lo quisi\u00e9ramos", "start": 2161.24, "duration": 4.48}, {"text": "tener en nuestro ordenador como vemos", "start": 2163.48, "duration": 4.119}, {"text": "aqu\u00ed hay diferentes par\u00e1metros otra vez", "start": 2165.72, "duration": 4.76}, {"text": "lo ten\u00e9is aqu\u00ed totalmente detallado les", "start": 2167.599, "duration": 4.76}, {"text": "vamos a indicar bueno Esto es el nombre", "start": 2170.48, "duration": 4.2}, {"text": "que le quer\u00e9is poner aqu\u00ed al al al", "start": 2172.359, "duration": 4.041}, {"text": "modelo en local luego le tenemos que", "start": 2174.68, "duration": 4.12}, {"text": "pasar Pues todos los tequiz adores y el", "start": 2176.4, "duration": 3.919}, {"text": "m\u00e9todo de guardado que le vamos a decir", "start": 2178.8, "duration": 4.08}, {"text": "que es el merch 16 bit como hemos visto", "start": 2180.319, "duration": 5.921}, {"text": "antes o sea Lora al final va se basa en", "start": 2182.88, "duration": 6.12}, {"text": "entrenar unos par\u00e1metros y Ser\u00eda posible", "start": 2186.24, "duration": 4.48}, {"text": "guardar solo estos par\u00e1metros entonces", "start": 2189.0, "duration": 2.76}, {"text": "aqu\u00ed lo que le estamos diciendo es que", "start": 2190.72, "duration": 3.8}, {"text": "no queremos que nos junte o sea nos", "start": 2191.76, "duration": 4.359}, {"text": "mezcle lo que son los par\u00e1metros con el", "start": 2194.52, "duration": 2.92}, {"text": "modelo para poderlo utilizar como si", "start": 2196.119, "duration": 3.521}, {"text": "fuese un modelo normal y el m\u00e9todo que", "start": 2197.44, "duration": 4.28}, {"text": "vamos a utilizar es el de 16 bits como", "start": 2199.64, "duration": 4.439}, {"text": "vemos aqu\u00ed repito lo ten\u00e9is aqu\u00ed todos", "start": 2201.72, "duration": 4.76}, {"text": "los par\u00e1metros de manera detallada", "start": 2204.079, "duration": 4.641}, {"text": "explicado y luego lo siguiente aqu\u00ed", "start": 2206.48, "duration": 3.8}, {"text": "tendr\u00edamos nuestro modelo guardado en", "start": 2208.72, "duration": 4.879}, {"text": "local lo pr\u00f3ximo ser\u00eda si lo queremos", "start": 2210.28, "duration": 5.559}, {"text": "publicar o tenerlos o tenerlo en un", "start": 2213.599, "duration": 4.801}, {"text": "repositorio central lo podr\u00edamos", "start": 2215.839, "duration": 4.881}, {"text": "publicar en haing Face repito al final", "start": 2218.4, "duration": 3.84}, {"text": "hing Face nos permite tener nuestro", "start": 2220.72, "duration": 3.599}, {"text": "modelo de manera privada si lo si as\u00ed lo", "start": 2222.24, "duration": 4.04}, {"text": "consideramos o lo podemos hacer de", "start": 2224.319, "duration": 4.52}, {"text": "manera p\u00fablica esto lo podemos ya", "start": 2226.28, "duration": 4.76}, {"text": "configurar directamente desde hacking", "start": 2228.839, "duration": 5.0}, {"text": "Face aqu\u00ed simplemente lo que vamos a", "start": 2231.04, "duration": 6.24}, {"text": "hacer es subir nuestro modelo a hf para", "start": 2233.839, "duration": 5.921}, {"text": "ello Este es mi nombre de usuario aqu\u00ed", "start": 2237.28, "duration": 3.96}, {"text": "le pondr\u00edamos el nombre que le vamos a", "start": 2239.76, "duration": 4.079}, {"text": "dar a nuestro modelo le pasamos otra vez", "start": 2241.24, "duration": 4.76}, {"text": "el el tokenizador le decimos el m\u00e9todo", "start": 2243.839, "duration": 4.201}, {"text": "de guardado que es el mismo y esto ser\u00eda", "start": 2246.0, "duration": 4.68}, {"text": "el token de haing Face que necesitamos", "start": 2248.04, "duration": 4.799}, {"text": "para poder hacer Push a nuestro", "start": 2250.68, "duration": 4.12}, {"text": "repositorio del modelo esto por un lado", "start": 2252.839, "duration": 4.641}, {"text": "nos guardar\u00eda el modelo pero luego por", "start": 2254.8, "duration": 4.92}, {"text": "otro lado tambi\u00e9n nos ofrece la", "start": 2257.48, "duration": 4.52}, {"text": "posibilidad de dar el modelo con", "start": 2259.72, "duration": 4.879}, {"text": "diferentes tipos de cuantizaci\u00f3n o sea", "start": 2262.0, "duration": 4.56}, {"text": "los que est\u00e1is acostumbrados eh o hab\u00e9is", "start": 2264.599, "duration": 3.681}, {"text": "visto por ejemplo el v\u00eddeo que hice", "start": 2266.56, "duration": 5.08}, {"text": "sobre lm Studio en hacking Face en el", "start": 2268.28, "duration": 5.6}, {"text": "repositorio bueno lm Studio en nutra de", "start": 2271.64, "duration": 3.88}, {"text": "haing Face podemos ver que un modelo", "start": 2273.88, "duration": 3.64}, {"text": "ten\u00eda diferentes tipos de cuantizaci\u00f3n y", "start": 2275.52, "duration": 4.12}, {"text": "pod\u00edamos escoger el que m\u00e1s nos conven\u00eda", "start": 2277.52, "duration": 4.04}, {"text": "seg\u00fan los recursos de nuestra m\u00e1quina", "start": 2279.64, "duration": 3.679}, {"text": "Pues bien Esto tambi\u00e9n es posible con", "start": 2281.56, "duration": 4.4}, {"text": "nuestro modelo entrenado subir todos los", "start": 2283.319, "duration": 5.161}, {"text": "diferentes qus para que tambi\u00e9n nos d\u00e9", "start": 2285.96, "duration": 4.84}, {"text": "esa opci\u00f3n y es lo que voy a hacer aqu\u00ed", "start": 2288.48, "duration": 4.68}, {"text": "a continuaci\u00f3n tenemos este m\u00e9todo que", "start": 2290.8, "duration": 5.0}, {"text": "nos permite aqu\u00ed nos permite pasar una", "start": 2293.16, "duration": 4.12}, {"text": "lista de todos los qu que vamos a", "start": 2295.8, "duration": 3.96}, {"text": "utilizar y subir todas estas versiones a", "start": 2297.28, "duration": 4.48}, {"text": "hing Face de la misma manera pas\u00e1ndole", "start": 2299.76, "duration": 3.88}, {"text": "los mismos par\u00e1metros y otra vez aqu\u00ed", "start": 2301.76, "duration": 4.28}, {"text": "necesitar\u00e9is vuestro token que lo pod\u00e9is", "start": 2303.64, "duration": 3.959}, {"text": "obtener aqu\u00ed os he dejado el link de", "start": 2306.04, "duration": 3.799}, {"text": "donde lo pod\u00e9is obtener y con esto pues", "start": 2307.599, "duration": 4.361}, {"text": "ya tendr\u00edamos nuestro modelo totalmente", "start": 2309.839, "duration": 4.28}, {"text": "publicado ahora os lo ense\u00f1ar\u00e9 en mi en", "start": 2311.96, "duration": 3.84}, {"text": "mi repositorio de haing Face como lo", "start": 2314.119, "duration": 3.841}, {"text": "tengo publicado yo lo har\u00e9 de manera", "start": 2315.8, "duration": 3.68}, {"text": "p\u00fablica si lo quer\u00e9is utilizar", "start": 2317.96, "duration": 3.28}, {"text": "bienvenidos todos pod\u00e9is utilizar Este", "start": 2319.48, "duration": 3.52}, {"text": "modelo que como veis al final est\u00e1 fint", "start": 2321.24, "duration": 3.96}, {"text": "tuneado para seguir instrucciones no lo", "start": 2323.0, "duration": 4.839}, {"text": "he testeado en demas\u00eda pero hasta lo que", "start": 2325.2, "duration": 4.879}, {"text": "he testeado es bastante preciso repito", "start": 2327.839, "duration": 4.201}, {"text": "os lo dejar\u00e9 p\u00fablico y lo pod\u00e9is probar", "start": 2330.079, "duration": 4.081}, {"text": "vosotros mismos este proceso de subida", "start": 2332.04, "duration": 5.0}, {"text": "evidentemente tarda unos minutos dir\u00eda", "start": 2334.16, "duration": 5.8}, {"text": "no unos 15 20 minutos puede ser que dure", "start": 2337.04, "duration": 5.72}, {"text": "y ya para terminar la nota importante si", "start": 2339.96, "duration": 5.159}, {"text": "hab\u00e9is llegado hasta aqu\u00ed os ha aportado", "start": 2342.76, "duration": 4.64}, {"text": "valor de verdad Este v\u00eddeo os", "start": 2345.119, "duration": 4.361}, {"text": "agradecer\u00eda much\u00edsimo que os suser que", "start": 2347.4, "duration": 4.32}, {"text": "me siguiera en mis redes sociales es la", "start": 2349.48, "duration": 4.52}, {"text": "manera de ayudarme a que pueda seguir", "start": 2351.72, "duration": 4.639}, {"text": "haciendo este contenido ya que realmente", "start": 2354.0, "duration": 5.28}, {"text": "lleva muchas horas hacer este tipo de", "start": 2356.359, "duration": 5.281}, {"text": "contenido tan detallado tan explicado en", "start": 2359.28, "duration": 5.6}, {"text": "detalle y adem\u00e1s en este caso costoso", "start": 2361.64, "duration": 5.719}, {"text": "as\u00ed que si os ha gustado por favor", "start": 2364.88, "duration": 4.08}, {"text": "Hacedme este favor os lo agradecer\u00e9", "start": 2367.359, "duration": 4.521}, {"text": "mucho seguidme suscribiros al Canal y Ah", "start": 2368.96, "duration": 4.8}, {"text": "bueno esta funci\u00f3n de aqu\u00ed es", "start": 2371.88, "duration": 5.28}, {"text": "porque al final encontr\u00e9 o sea encontr\u00e9", "start": 2373.76, "duration": 5.96}, {"text": "este m\u00e9todo que no lo hab\u00eda encontrado", "start": 2377.16, "duration": 4.88}, {"text": "al principio que nos permite subir como", "start": 2379.72, "duration": 4.119}, {"text": "dec\u00eda Eh pues todas las versiones con", "start": 2382.04, "duration": 3.64}, {"text": "todos los qu disponibles lo encontr\u00e9", "start": 2383.839, "duration": 4.0}, {"text": "despu\u00e9s antes de encontrarlo lo que", "start": 2385.68, "duration": 4.72}, {"text": "hab\u00eda hecho es una funci\u00f3n para eh", "start": 2387.839, "duration": 5.721}, {"text": "utilizando pues la opci\u00f3n principal que", "start": 2390.4, "duration": 5.08}, {"text": "hab\u00e9is visto arriba con la que subo el", "start": 2393.56, "duration": 4.68}, {"text": "modelo tal cual pues utilizando esta", "start": 2395.48, "duration": 5.52}, {"text": "pues me hizo una funci\u00f3n recursiva para", "start": 2398.24, "duration": 5.599}, {"text": "poder subir todos los qu os la he dejado", "start": 2401.0, "duration": 4.88}, {"text": "aqu\u00ed por si por si quer\u00e9is esta funci\u00f3n", "start": 2403.839, "duration": 4.881}, {"text": "recursiva Pero bueno eh recomiendo como", "start": 2405.88, "duration": 4.959}, {"text": "est\u00e1 aqu\u00ed arriba utilizar el el otro", "start": 2408.72, "duration": 4.32}, {"text": "m\u00e9todo ya que es el que est\u00e1 preparado", "start": 2410.839, "duration": 4.201}, {"text": "especialmente para esto bien por \u00faltimo", "start": 2413.04, "duration": 3.039}, {"text": "me queda ense\u00f1aros d\u00f3nde pod\u00e9is", "start": 2415.04, "duration": 3.72}, {"text": "encontrar el modelo que tambi\u00e9n que", "start": 2416.079, "duration": 4.921}, {"text": "sirva como prueba que realmente he", "start": 2418.76, "duration": 4.839}, {"text": "entrenado estos modelos los ten\u00e9is aqu\u00ed", "start": 2421.0, "duration": 5.839}, {"text": "en mi hacking Face ten\u00e9is la la opci\u00f3n", "start": 2423.599, "duration": 6.24}, {"text": "normal y la opci\u00f3n con todos los qu", "start": 2426.839, "duration": 6.401}, {"text": "disponibles como pod\u00e9is ver por aqu\u00ed con", "start": 2429.839, "duration": 6.401}, {"text": "los diferentes tipos de precisi\u00f3n repito", "start": 2433.24, "duration": 4.8}, {"text": "os lo dejar\u00e9 p\u00fablico lo pod\u00e9is utilizar", "start": 2436.24, "duration": 3.76}, {"text": "si lo utiliz\u00e1is me gustar\u00eda saberlo y", "start": 2438.04, "duration": 3.52}, {"text": "que me dej\u00e1is un feedback y me dig\u00e1is", "start": 2440.0, "duration": 3.28}, {"text": "que os ha parecido Este modelo si os ha", "start": 2441.56, "duration": 4.559}, {"text": "parecido \u00fatil tambi\u00e9n sin m\u00e1s eh que", "start": 2443.28, "duration": 5.48}, {"text": "este v\u00eddeo se ha hecho largo Espero que", "start": 2446.119, "duration": 4.641}, {"text": "os haya gustado nos vemos en el", "start": 2448.76, "duration": 4.16}, {"text": "siguiente v\u00eddeo que va a ser creo que", "start": 2450.76, "duration": 3.76}, {"text": "igual m\u00e1s interesante que este", "start": 2452.92, "duration": 5.24}, {"text": "suscribiros para no perderlo", "start": 2454.52, "duration": 3.64}]